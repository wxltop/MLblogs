import{_ as l,r as e,o as p,c as i,a as s,b as a,d as c,e as n}from"./app-aa9cafec.js";const o="/MLblogs/assets/2024-09-05-21-19-33-image-f94d642f.png",m="/MLblogs/assets/2024-09-05-21-20-32-image-52467bcb.png",r="/MLblogs/assets/2024-09-05-21-32-31-image-2509ab8c.png",u="/MLblogs/assets/2024-09-05-21-32-05-image-2da415c7.png",h="/MLblogs/assets/2024-09-05-21-33-59-image-386905dd.png",d="/MLblogs/assets/2024-08-26-12-03-40-image-496215bb.png",g="/MLblogs/assets/2024-08-26-12-03-55-image-37620c9f.png",k="/MLblogs/assets/2024-08-26-12-04-14-image-bea41a9f.png",v="/MLblogs/assets/2024-08-26-12-05-07-image-d7bbf075.png",y="/MLblogs/assets/2024-08-26-12-05-33-image-e050de5b.png",b="/MLblogs/assets/2024-10-22-23-33-48-image-bc2c570d.png",x="/MLblogs/assets/2024-09-02-08-37-50-image-597c190e.png",w="/MLblogs/assets/2024-09-02-09-40-42-image-fb24a387.png",f="/MLblogs/assets/2024-09-02-09-43-03-image-fe74140a.png",_="/MLblogs/assets/2024-09-02-09-42-18-image-e338889f.png",z="/MLblogs/assets/2024-09-02-09-04-02-image-22d73b99.png",M={},L=n('<h2 id="梯度消失和梯度爆炸" tabindex="-1"><a class="header-anchor" href="#梯度消失和梯度爆炸" aria-hidden="true">#</a> 梯度消失和梯度爆炸</h2><h2 id="训练loss为nan或inf" tabindex="-1"><a class="header-anchor" href="#训练loss为nan或inf" aria-hidden="true">#</a> 训练loss为nan或inf</h2><ul><li><p>NaN和INF：</p><ul><li><p>NaN 表示一个未定义或不可表示的值。例如，0 除以 0、无穷大减去无穷大</p><ul><li>导致原因：数学运算错误，如上面提到的不合法运算。</li></ul></li><li><p>INF 表示无穷大。在数值计算中，当一个数变得非常大超出了数据类型所能表示的范围时，就会被表示为 INF。</p><ul><li>数值计算中的溢出，例如当一个非常大的数进行乘法运算或者除以一个非常接近 0 的数时。</li></ul></li></ul></li><li><p>原因分析：</p><ul><li><p>数值溢出。如：</p><ul><li>梯度爆炸：在模型训练过程中，梯度更新过大，导致数值溢出。例如，当神经网络层数很深或者学习率设置过高时，梯度在反向传播过程中可能会不断增大，最终导致数值溢出，使得 loss 变为 INF。</li></ul></li><li><p>数据问题。如：</p><ul><li><p>异常值：数据中存在极大或极小的异常值，这些异常值在计算损失函数时可能会导致数值不稳定。例如，在回归问题中，如果有一个离群的数据点，其值远远超出其他数据点的范围，可能会使损失函数变得很大甚至无穷大。</p></li><li><p>数据不规范：数据没有进行适当的归一化或标准化处理，导致不同特征的数值范围差异很大。在计算损失函数时，较大数值的特征可能会主导计算，从而导致数值不稳定。</p></li></ul></li><li><p>模型问题：</p><ul><li>初始化不当：模型参数的初始化不合理，可能会导致训练过程中出现数值问题。例如，如果权重初始值过大或过小，可能会使神经元的输出在训练初期就变得非常大或非常小，进而影响损失函数的计算。</li></ul></li></ul></li></ul><h2 id="权重初始化方法" tabindex="-1"><a class="header-anchor" href="#权重初始化方法" aria-hidden="true">#</a> 权重初始化方法</h2><h2 id="rnn-vs-lstm-vs-gru-vs-transformer" tabindex="-1"><a class="header-anchor" href="#rnn-vs-lstm-vs-gru-vs-transformer" aria-hidden="true">#</a> RNN vs LSTM vs GRU vs Transformer</h2><p><strong>RNN</strong>：</p><ul><li><p>RNN 是一种具有循环结构的神经网络，它可以处理任意长度的序列数据。在 RNN 中，每个时间步的隐藏状态不仅取决于当前的输入，还取决于上一个时间步的隐藏状态。</p></li><li><p>这种循环结构使得 RNN 能够捕捉序列数据中的时间依赖关系，但也带来了一些问题，如长期依赖问题和梯度消失 / 爆炸问题。</p></li><li><p>缺点：</p><ul><li>由于RNN这种特殊的循环结构，每一步的状态都包含了上一个状态的输出，因此根据链式法则在反向传播求导的时候，越早的项连续相乘的部分就会越长。在处理长序列数据的时候，若连续相乘的项很小就有梯度消失的问题，而相反相乘项比较大的时候就会出现梯度爆炸的问题。</li></ul></li><li><p>公式：h是上一个状态的输出，x是当前的输入</p></li></ul><img title="" src="'+o+'" alt="" data-align="center" width="400"><p><strong>LSTM</strong>：</p><ul><li><p>引入门控机制来解决 RNN 的长期依赖问题和梯度消失 / 爆炸问题。</p></li><li><p>输入门：决定哪些新的信息将被存储到记忆单元中</p></li><li><p>遗忘门：决定从记忆单元中丢弃哪些信息</p></li><li><p>输出门：控制记忆单元状态中有多少信息被输出到隐藏状态中</p></li><li><p>记忆单元：它负责存储和传递长期信息。它贯穿整个时间序列，通过遗忘门和输入门的控制，不断更新和保存信息</p></li><li><p>激活函数：<strong>sigmoid</strong>：在遗忘门、输入门和输出门中使用。其作用是将输入值压缩到0到1之间，以便决定有多少信息被遗忘、输入或输出。<strong>tanh</strong>：在计算候选细胞状态时使用。它将输入值压缩到-1到1之间，用于生成新的细胞状态的候选值。例如，在输入门中，通过对输入信息进行处理，得到一个候选细胞状态，这个过程中使用了 Tanh 函数。</p></li><li><p>缺点：训练时间较长，计算量大</p></li></ul><p>LSTM结构如下：</p>',11),N=s("p",null,[a("黄色小框从左到右依次为："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f")]),s("annotation",{encoding:"application/x-tex"},"f")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),a("为遗忘门、"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"i")]),s("annotation",{encoding:"application/x-tex"},"i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6595em"}}),s("span",{class:"mord mathnormal"},"i")])])]),a("输入门（中间俩小框）、"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"o")]),s("annotation",{encoding:"application/x-tex"},"o")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"o")])])]),a("输出门。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"t")]),s("mtext",null,"​")]),s("annotation",{encoding:"application/x-tex"},"x_t​")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},"​")])])]),a("为输入向量"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"h"),s("mi",null,"t")])]),s("annotation",{encoding:"application/x-tex"},"h_t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"h"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("为隐藏状态向量，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"C"),s("mi",null,"h")])]),s("annotation",{encoding:"application/x-tex"},"C_h")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0715em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"h")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("​为细胞状态向量。一共有两个tanh，三个sigma，四个权重W。")],-1),P=n('<img src="'+m+'" title="" alt="" data-align="center"><p><strong>GRU</strong>：</p><img title="" src="'+r+'" alt="" width="215" data-align="center"><img title="" src="'+u+'" alt="" width="279" data-align="center"><p><strong>Transformer</strong>：</p><ul><li><p>并行计算：能够并行地处理序列数据，大大提高了计算效率。</p></li><li><p>对于短序列数据，Transformer 可能不如 RNN 和 LSTM 有效。</p></li><li><p>强大的建模能力：通过多头注意力机制，Transformer 能够捕捉序列中的全局依赖关系，对长序列数据的建模能力更强。</p></li></ul><img title="" src="'+h+`" alt="" width="418" data-align="center"><h2 id="逻辑回归" tabindex="-1"><a class="header-anchor" href="#逻辑回归" aria-hidden="true">#</a> 逻辑回归</h2><p>手撕代码：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> num_iterations<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>learning_rate <span class="token operator">=</span> learning_rate
        self<span class="token punctuation">.</span>num_iterations <span class="token operator">=</span> num_iterations
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_samples<span class="token punctuation">,</span> num_features <span class="token operator">=</span> X<span class="token punctuation">.</span>shape
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
            linear_model <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias
            y_predicted <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>linear_model<span class="token punctuation">)</span>

            dw <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> num_samples<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> <span class="token punctuation">(</span>y_predicted <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
            db <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> num_samples<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_predicted <span class="token operator">-</span> y<span class="token punctuation">)</span>

            self<span class="token punctuation">.</span>weights <span class="token operator">-=</span> self<span class="token punctuation">.</span>learning_rate <span class="token operator">*</span> dw
            self<span class="token punctuation">.</span>bias <span class="token operator">-=</span> self<span class="token punctuation">.</span>learning_rate <span class="token operator">*</span> db

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        linear_model <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias
        y_predicted <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>linear_model<span class="token punctuation">)</span>
        y_predicted_class <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span> <span class="token keyword">if</span> i <span class="token operator">&gt;</span> <span class="token number">0.5</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> y_predicted<span class="token punctuation">]</span>
        <span class="token keyword">return</span> y_predicted_class
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>理论部分：</p><p>逻辑回归是一种用于<strong>分类问题</strong>的机器学习算法，逻辑回归通常使用<strong>交叉熵损失函数</strong>，对于单个样本，交叉熵损失如下：</p>`,12),Q=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",null,"−"),s("mi",null,"y"),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"y"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L(y, \\hat{y})=-y \\log (\\hat{y})-(1-y) \\log (1-\\hat{y}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mclose"},")")])])])])],-1),q=s("p",null,"对于整个数据集，损失函数为所有样本损失的平均值：",-1),T=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"J"),s("mo",{stretchy:"false"},"("),s("mi",null,"w"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"m")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"m")]),s("mo",null,"−"),s("msup",null,[s("mi",null,"y"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mi",null,"log"),s("mo",null,"⁡"),s("mrow",null,[s("mo",{fence:"true"},"("),s("msup",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mo",{fence:"true"},")")]),s("mo",null,"−"),s("mrow",null,[s("mo",{fence:"true"},"("),s("mn",null,"1"),s("mo",null,"−"),s("msup",null,[s("mi",null,"y"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mo",{fence:"true"},")")]),s("mi",null,"log"),s("mo",null,"⁡"),s("mrow",null,[s("mo",{fence:"true"},"("),s("mn",null,"1"),s("mo",null,"−"),s("msup",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mo",{fence:"true"},")")])]),s("annotation",{encoding:"application/x-tex"}," J(w)=\\frac{1}{m} \\sum_{i=1}^m-y^{(i)} \\log \\left(\\hat{y}^{(i)}\\right)-\\left(1-y^{(i)}\\right) \\log \\left(1-\\hat{y}^{(i)}\\right) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"m")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"m")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},"(")]),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},")")])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.8em","vertical-align":"-0.65em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},"(")]),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},")")])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},"(")]),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},")")])])])])])])],-1),K=s("p",null,"梯度计算的推导：",-1),D=s("img",{title:"",src:d,alt:"",width:"225"},null,-1),H=s("img",{src:g,title:"",alt:"",width:"144"},null,-1),R=s("img",{src:k,title:"",alt:"",width:"258"},null,-1),j=s("p",null,[a("在批量数据上，计算梯度时是对所有样本的梯度求平均。例如对于权重"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mi",null,"j")])]),s("annotation",{encoding:"application/x-tex"},"w_j")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),a("，梯度为：")],-1),O=n('<img src="'+v+'" title="" alt="" width="156"><p>其中m是样本数量。对于偏置b，梯度为：</p><img title="" src="'+y+'" alt="" width="132"><h2 id="交叉熵损失推导" tabindex="-1"><a class="header-anchor" href="#交叉熵损失推导" aria-hidden="true">#</a> 交叉熵损失推导</h2><p>交叉熵和似然函数的关系：</p><ul><li><strong>极大似然估计（Maximum Likelihood Estimation，MLE）</strong>：它是一种统计方法，用于估计概率模型的参数。给定一组观测数据，假设数据是独立同分布（i.i.d）的，极大似然估计的目标是找到一组模型参数，使得观测数据出现的概率（似然函数）最大。</li><li>当使用交叉熵损失函数时，本质上是在进行极大似然估计。</li><li><img src="'+b+`" title="" alt="" data-align="center"></li></ul><p>手撕：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">cross_entropy_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    epsilon <span class="token operator">=</span> <span class="token number">1e-15</span>
    y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>clip<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> epsilon<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> epsilon<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_true <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_true<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>熵和KL散度的关系</strong>：</p><p>相对熵即KL 散度，用于衡量两个概率分布之间的差异。如果有两个概率分布P(x)和Q(x)，则它们之间的 KL 散度定义为：</p>`,10),B=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"D"),s("mrow",null,[s("mi",null,"K"),s("mi",null,"L")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"P"),s("mi",{mathvariant:"normal"},"∥"),s("mi",null,"Q"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("munder",null,[s("mo",null,"∑"),s("mi",null,"x")]),s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mfrac",null,[s("mrow",null,[s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])])]),s("annotation",{encoding:"application/x-tex"}," D_{K L}(P \\| Q)=\\sum_x P(x) \\log \\frac{P(x)}{Q(x)} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mord mathnormal mtight"},"L")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mord"},"∥"),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.677em","vertical-align":"-1.25em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.9em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),S=s("p",null,"展开得到：",-1),C=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"D"),s("mrow",null,[s("mi",null,"K"),s("mi",null,"L")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"P"),s("mi",{mathvariant:"normal"},"∥"),s("mi",null,"Q"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("munder",null,[s("mo",null,"∑"),s("mi",null,"x")]),s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("munder",null,[s("mo",null,"∑"),s("mi",null,"x")]),s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," D_{K L}(P \\| Q)=\\sum_x P(x) \\log P(x)-\\sum_x P(x) \\log Q(x) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mord mathnormal mtight"},"L")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mord"},"∥"),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3em","vertical-align":"-1.25em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.9em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3em","vertical-align":"-1.25em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.9em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])])])],-1),F=s("p",null,"交叉熵的引出：",-1),E=s("p",null,"变形KL散度：",-1),G=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"D"),s("mrow",null,[s("mi",null,"K"),s("mi",null,"L")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"P"),s("mi",{mathvariant:"normal"},"∥"),s("mi",null,"Q"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"H"),s("mo",{stretchy:"false"},"("),s("mi",null,"P"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"H"),s("mo",{stretchy:"false"},"("),s("mi",null,"P"),s("mo",{separator:"true"},","),s("mi",null,"Q"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," D_{K L}(P \\| Q)=H(P)-H(P, Q) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mord mathnormal mtight"},"L")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mord"},"∥"),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mclose"},")")])])])])],-1),I=s("p",null,[a("其中H(P,Q)为："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"H"),s("mo",{stretchy:"false"},"("),s("mi",null,"P"),s("mo",{separator:"true"},","),s("mi",null,"Q"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",null,"−"),s("msub",null,[s("mo",null,"∑"),s("mi",null,"x")]),s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"H(P, Q)=-\\sum_x P(x) \\log Q(x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0497em","vertical-align":"-0.2997em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.0017em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2997em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),a("，是P和Q的交叉熵。")],-1),V=n(`<p>在分类问题中，真实分布P(x)是已知的（即样本的真实标签），我们希望通过模型得到的预测分布Q(x)尽可能接近真实分布。此时最小化 KL 散度等价于最小化交叉熵，因为真实分布的信息熵是固定的。</p><p>所以，通过信息熵、KL 散度的定义推导出了交叉熵损失函数，它在分类问题中被广泛用于衡量模型预测分布与真实分布之间的差异。</p><h2 id="手撕softmax" tabindex="-1"><a class="header-anchor" href="#手撕softmax" aria-hidden="true">#</a> 手撕softmax</h2><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">softmax_with_temperature</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    max_val <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    exp_x <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> max_val<span class="token punctuation">)</span> <span class="token operator">/</span> temperature<span class="token punctuation">)</span>  <span class="token comment"># 防止exp太大溢出</span>
    sum_exp_x <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>exp_x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> exp_x <span class="token operator">/</span> sum_exp_x
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>温度系数：</p><ol><li><p>高温（温度系数较大）</p><ul><li>当温度系数增大时，Softmax 函数的输出分布会变得更加平滑。这意味着各个类别的概率值更加接近，模型对不同类别的区分度降低。在一些情况下，这可以鼓励模型探索更多的可能性，避免过度自信地选择某个特定类别。</li><li>例如，在模型集成或模型不确定性估计中，可以使用较高的温度系数来获得多个模型预测的平均分布，从而更好地了解模型的不确定性。</li></ul></li><li><p>低温（温度系数较小）</p><ul><li>相反，当温度系数减小时，Softmax 函数的输出分布会变得更加尖锐。这会使模型更加确定地选择某个类别，概率集中在高概率的类别上。</li><li>对于一些需要明确决策的任务，如最终的分类预测，可以使用较低的温度系数来增强模型的确定性。</li></ul></li></ol><h2 id="auc" tabindex="-1"><a class="header-anchor" href="#auc" aria-hidden="true">#</a> AUC</h2><p>手撕：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">calculate_auc</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_score<span class="token punctuation">)</span><span class="token punctuation">:</span>
    rank <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_score<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    neg <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> rn <span class="token keyword">in</span> rank<span class="token punctuation">:</span>
        <span class="token keyword">if</span> rn<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> neg<span class="token punctuation">:</span>
            neg<span class="token punctuation">[</span>rn<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">if</span> rn<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            neg<span class="token punctuation">[</span>rn<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

    M <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>y_true<span class="token punctuation">)</span>
    N <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_true<span class="token punctuation">)</span> <span class="token operator">-</span> M

    auc <span class="token operator">=</span> <span class="token number">0</span>
    pre_neg <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>rank<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> rank<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            pre_neg <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            auc <span class="token operator">+=</span> <span class="token number">1.0</span> <span class="token operator">*</span> <span class="token punctuation">(</span>N <span class="token operator">-</span> pre_neg <span class="token operator">-</span> neg<span class="token punctuation">[</span>rank<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            auc <span class="token operator">+=</span> <span class="token number">0.5</span> <span class="token operator">*</span> neg<span class="token punctuation">[</span>rank<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> auc <span class="token operator">/</span> <span class="token punctuation">(</span>M <span class="token operator">*</span> N<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>auc的物理含义：正样本打分高于负样本的概率（正样本排在前面的概率）</p><h2 id="二分类评估指标" tabindex="-1"><a class="header-anchor" href="#二分类评估指标" aria-hidden="true">#</a> 二分类评估指标</h2><h2 id="why均方误差不用于分类" tabindex="-1"><a class="header-anchor" href="#why均方误差不用于分类" aria-hidden="true">#</a> why均方误差不用于分类</h2><ol><li><p>在接近结果值时，梯度趋近于零，更新缓慢</p></li><li><p>对错误的惩罚力度不够，比如模型若对于label=1的样本的预测值为0.55，可能惩罚很小</p></li></ol><h2 id="gbdt" tabindex="-1"><a class="header-anchor" href="#gbdt" aria-hidden="true">#</a> GBDT</h2><p>能否做分类？</p><h2 id="dropout" tabindex="-1"><a class="header-anchor" href="#dropout" aria-hidden="true">#</a> Dropout</h2><p>为何回归问题不建议用dropout</p><h2 id="why-normalization" tabindex="-1"><a class="header-anchor" href="#why-normalization" aria-hidden="true">#</a> why normalization?</h2><h2 id="欠拟合和过拟合" tabindex="-1"><a class="header-anchor" href="#欠拟合和过拟合" aria-hidden="true">#</a> 欠拟合和过拟合</h2><p>如何缓解？</p><p>如何判断？</p><h2 id="transformer" tabindex="-1"><a class="header-anchor" href="#transformer" aria-hidden="true">#</a> Transformer</h2><p><strong>位置编码</strong>：</p><ul><li><p>使用的是正弦余弦位置编码。因为正余弦之间的转变容易，方便模型学习不同位置的联系。</p></li><li><p>此外，还有可学习的位置编码，如bert用的。</p></li><li><p>还有相对位置编码，重点关注序列中词与词之间的相对位置关系，而不是绝对位置。</p></li><li><p>混合位置编码：结合多种位置编码方式，以充分利用它们的优点</p></li></ul><p><strong>transformer中的mask</strong>：</p><ul><li><p>padding mask：在处理序列数据时，不同的输入序列长度可能不一致。为了能够将这些序列批量处理，通常会将较短的序列进行填充（padding）</p><ul><li>填充值应该是负无穷而不是0</li></ul></li><li><p>下三角掩码：在解码器中使用，用于确保在预测当前位置的输出时，只使用当前位置之前的信息，而不使用未来的信息。</p><ul><li>是一个下三角矩阵，其中上三角部分的值为负无穷或一个非常小的值，下三角部分和对角线的值为零或一</li></ul></li></ul><p>如果将transformer中的QK变成同一个矩阵，影响大吗？</p><ul><li>Q 和 K 在 Transformer 中原本有不同的作用。Query 通常代表目标位置的查询向量，用于关注其他位置的信息以更新自身表示；Key 则是被查询的向量，用于提供与其他位置的关联信息。将它们合并为一个矩阵会丧失这种区分，可能导致模型难以准确区分不同位置的重要性和相关性。</li></ul><p>MHA的时间复杂度：</p><p>假设输入序列长度为n，隐藏层维度为d，头的数量为h。</p>`,30),X=s("p",null,[a("对于单个头：QKV线性变换的时间复杂度为："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"O"),s("mo",{stretchy:"false"},"("),s("mi",null,"n"),s("msup",null,[s("mi",null,"d"),s("mn",null,"2")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"O(nd^2)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mclose"},")")])])]),a("，QK的复杂度："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"O"),s("mo",{stretchy:"false"},"("),s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"n"),s("mn",null,"2")]),s("mi",null,"d")]),s("mi",null,"h")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"O(\\frac{n^2d}{h})")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.3629em","vertical-align":"-0.345em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0179em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"h")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mord mathnormal mtight"},"d")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")")])])]),a("，softmax的复杂度："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"O"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"n"),s("mn",null,"2")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"O(n^2)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"n"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mclose"},")")])])]),a("，att与V相乘的复杂度："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"O"),s("mo",{stretchy:"false"},"("),s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"n"),s("mn",null,"2")]),s("mi",null,"d")]),s("mi",null,"h")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"O(\\frac{n^2d}{h})")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.3629em","vertical-align":"-0.345em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0179em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"h")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mord mathnormal mtight"},"d")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")")])])]),a("。")],-1),A=n(`<p><strong>手撕MHA</strong>：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">MHA</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> nheads<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>wq <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>wk <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>wv <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>o <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>nheads <span class="token operator">=</span> nheads

    <span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        max_val <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        exp <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> max_val<span class="token punctuation">)</span> <span class="token operator">/</span> t<span class="token punctuation">)</span>
        <span class="token keyword">return</span> exp <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>exp<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">:</span>
        b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> dim <span class="token operator">=</span> q<span class="token punctuation">.</span>shape<span class="token punctuation">(</span><span class="token punctuation">)</span>
        m_dim <span class="token operator">=</span> dim <span class="token operator">//</span> self<span class="token punctuation">.</span>nheads

        q <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>q<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>wq<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> self<span class="token punctuation">.</span>nheads<span class="token punctuation">,</span> m_dim<span class="token punctuation">)</span>
        k <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>k<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>wk<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> self<span class="token punctuation">.</span>nheads<span class="token punctuation">,</span> m_dim<span class="token punctuation">)</span>
        v <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>v<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>wv<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> self<span class="token punctuation">.</span>nheads<span class="token punctuation">,</span> m_dim<span class="token punctuation">)</span>

        att_scores <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>m_dim<span class="token punctuation">)</span>
        att_weight <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>att_scores<span class="token punctuation">)</span>

        out <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>att_weight<span class="token punctuation">,</span> v<span class="token punctuation">)</span>  <span class="token comment"># b, n, h, d</span>

        final_out <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>o<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        <span class="token keyword">return</span> final_out
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="优化器" tabindex="-1"><a class="header-anchor" href="#优化器" aria-hidden="true">#</a> 优化器</h2><h3 id="梯度下降" tabindex="-1"><a class="header-anchor" href="#梯度下降" aria-hidden="true">#</a> 梯度下降</h3><ul><li><p>SGD：随机梯度下降，<strong>每次使用一个样本</strong></p></li><li><p>BGD：批量梯度下降，<strong>每次使用全部样本</strong></p></li><li><p>MBGD：小批量梯度下降，<strong>每次使用部分样本</strong></p></li></ul><p>缺点：对学习率敏感，过大时反复横跳，容易卡在鞍点位置</p><h3 id="动量" tabindex="-1"><a class="header-anchor" href="#动量" aria-hidden="true">#</a> 动量：</h3><p>跳出最小值</p><h3 id="adam" tabindex="-1"><a class="header-anchor" href="#adam" aria-hidden="true">#</a> Adam：</h3><p>偏差纠正：一开始时，累积量接近于0，加上偏差纠正可以缓解</p><p>手撕梯度下降求解一元二次方程：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">compute_grad</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span> <span class="token operator">*</span> a <span class="token operator">*</span> x <span class="token operator">+</span> b


<span class="token keyword">def</span> <span class="token function">gradient_descent</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> x0<span class="token punctuation">,</span> num_iter<span class="token punctuation">,</span> lr<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> x0
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
        grad <span class="token operator">=</span> compute_grad<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x <span class="token operator">-</span> lr <span class="token operator">*</span> grad
    <span class="token keyword">return</span> x


<span class="token comment"># y = a * x ^ 2 + b * x + c</span>
a <span class="token operator">=</span> <span class="token number">2</span>
b <span class="token operator">=</span> <span class="token number">3</span>
c <span class="token operator">=</span> <span class="token number">1</span>

initial_x <span class="token operator">=</span> <span class="token number">0.</span>
lr <span class="token operator">=</span> <span class="token number">0.1</span>
num_iteration <span class="token operator">=</span> <span class="token number">1000</span>

ans <span class="token operator">=</span> gradient_descent<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> initial_x<span class="token punctuation">,</span> num_iteration<span class="token punctuation">,</span> lr<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>ans<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="ln-vs-bn" tabindex="-1"><a class="header-anchor" href="#ln-vs-bn" aria-hidden="true">#</a> LN vs BN</h2><p>LN 与批归一化（Batch Normalization）不同，层归一化是对单个样本的特征维度进行归一化，而不是对一批样本进行归一化</p><p><strong>手撕LN</strong>：</p>`,15),J=s("p",null,[a("公式如下，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"μ")]),s("annotation",{encoding:"application/x-tex"},"\\mu")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"μ")])])]),a("是均值，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"σ"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"\\sigma^2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])]),a("是方差，归一化之后的形状和输入形状相同，都是(bs, seq_len, dim)：")],-1),U=s("img",{title:"",src:x,alt:"",width:"172"},null,-1),W=s("p",null,[a("引入缩放和平移：引入可学习参数"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"γ"),s("mo",{separator:"true"},","),s("mi",null,"β")]),s("annotation",{encoding:"application/x-tex"},"\\gamma,\\beta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β")])])]),a("，形状都是(dim, )，对归一化后的张量进行缩放和平移，公式为："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("msub",null,[s("mi",null,"x"),s("mtext",null,"normalized")]),s("mo",null,"∗"),s("mi",null,"γ"),s("mo",null,"+"),s("mi",null,"β")]),s("annotation",{encoding:"application/x-tex"},"y=x_{\\text{normalized}}*\\gamma+\\beta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6153em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"normalized")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β")])])]),a("，y是最终的输出，与输入的shape相同")],-1),Y=n(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">layer_normalization</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> embedding_dim <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    var <span class="token operator">=</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    normalized_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
    <span class="token keyword">return</span> gamma <span class="token operator">*</span> normalized_x <span class="token operator">+</span> beta
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>手撕BN：</strong></p><p>BN可以加速模型的训练、提高模型的泛化能力，并减少对初始化的敏感性。批归一化通过对每个小批量数据的特征进行归一化，使得数据的分布更加稳定</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">batch_normalization</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_size<span class="token punctuation">,</span> num_channels <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token comment"># 计算均值</span>
    mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># 计算方差</span>
    var <span class="token operator">=</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># 归一化</span>
    normalized_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
    <span class="token comment"># 缩放和平移</span>
    <span class="token keyword">return</span> gamma <span class="token operator">*</span> normalized_x <span class="token operator">+</span> beta
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="loss" tabindex="-1"><a class="header-anchor" href="#loss" aria-hidden="true">#</a> loss</h2><h3 id="bpr-loss" tabindex="-1"><a class="header-anchor" href="#bpr-loss" aria-hidden="true">#</a> BPR Loss</h3><p>专门用在推荐系统，旨在优化排序任务，最大化用户对正样本的偏好概率，最小化用户对负样本的偏好概率：</p>`,7),Z=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",null,"="),s("mo",null,"−"),s("munder",null,[s("mo",null,"∑"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"u"),s("mo",{separator:"true"},","),s("mi",null,"i"),s("mo",{separator:"true"},","),s("mi",null,"j"),s("mo",{stretchy:"false"},")"),s("mo",null,"∈"),s("mi",null,"D")])]),s("mi",null,"ln"),s("mo",null,"⁡"),s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mrow",null,[s("mi",null,"u"),s("mo",{separator:"true"},","),s("mi",null,"i")])]),s("mo",null,"−"),s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mrow",null,[s("mi",null,"u"),s("mo",{separator:"true"},","),s("mi",null,"j")])]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L=-\\sum_{(u,i,j)\\in D}\\ln\\sigma(\\hat{y}_{u,i}-\\hat{y}_{u,j}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.566em","vertical-align":"-1.516em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.809em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"u"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mclose mtight"},")"),s("span",{class:"mrel mtight"},"∈"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"D")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.516em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},"ln"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"u"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0361em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"u"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])])])],-1),$=s("h3",{id:"hinge-loss",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#hinge-loss","aria-hidden":"true"},"#"),a(" Hinge Loss")],-1),ss=s("p",null,"通常用于支持向量机和其他分类任务，特别是二分类问题，主要用于最大化边界：",-1),as=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"H"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"g"),s("mi",null,"e")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"max"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"y"),s("mo",null,"∗"),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L_{Hinge}(y,\\hat{y})=\\max(0,1-y*\\hat{y}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0361em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"mord mathnormal mtight"},"in"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal mtight"},"e")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6597em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mclose"},")")])])])])],-1),ns=s("p",null,"其中y是真实标签（正为1，负为-1）",-1),ts=s("h3",{id:"triplet-loss",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#triplet-loss","aria-hidden":"true"},"#"),a(" triplet loss")],-1),ls=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",null,"="),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mi",null,"d"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mo",{separator:"true"},","),s("mi",null,"p"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"m"),s("mo",null,"−"),s("mi",null,"d"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mo",{separator:"true"},","),s("mi",null,"n"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L=max(0, d(a,p)+m-d(a, n) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mclose"},")")])])])])],-1),es=s("h3",{id:"focal-loss",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#focal-loss","aria-hidden":"true"},"#"),a(" focal loss")],-1),ps={href:"https://blog.csdn.net/wzk4869/article/details/131736518",target:"_blank",rel:"noopener noreferrer"},is=s("p",null,[a("针对正负样本不平衡问题的改进函数，考虑了样本的难易程度，相比交叉熵，其通过调节因子"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"γ")]),s("annotation",{encoding:"application/x-tex"},"\\gamma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ")])])]),a("对易分类样本降低损失权重，使模型更关注难样本（预测值在0.5附近）")],-1),cs=n('<img title="" src="'+w+'" alt="" width="256" data-align="center"><img title="" src="'+f+'" alt="" width="369" data-align="center"><img title="" src="'+_+`" alt="" data-align="center" width="316"><p>手撕：(二分类)</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">clip</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> seq <span class="token operator">&lt;</span> <span class="token builtin">min</span><span class="token punctuation">:</span>
            seq<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">min</span>
        <span class="token keyword">elif</span> seq <span class="token operator">&gt;</span> <span class="token builtin">max</span><span class="token punctuation">:</span>
            seq<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">max</span>
    <span class="token keyword">return</span> seq

<span class="token keyword">def</span> <span class="token function">get_pt</span><span class="token punctuation">(</span>label<span class="token punctuation">,</span> pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pt <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> l<span class="token punctuation">,</span> p <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>label<span class="token punctuation">,</span> pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> l <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            pt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            pt<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> p<span class="token punctuation">)</span>
    <span class="token keyword">return</span> pt


<span class="token keyword">def</span> <span class="token function">focal_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Focal Loss implementation.

    Parameters:
    y_true: True labels.
    y_pred: Predicted probabilities.
    gamma: Focusing parameter (default is 2.0).
    alpha: Class balancing parameter (default is 0.25).

    Returns:
    Focal loss value.
    &quot;&quot;&quot;</span>
    epsilon <span class="token operator">=</span> <span class="token number">1e-7</span>
    y_pred <span class="token operator">=</span> clip<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> epsilon<span class="token punctuation">,</span> <span class="token number">1.</span> <span class="token operator">-</span> epsilon<span class="token punctuation">)</span>
    pt <span class="token operator">=</span> get_pt<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span>alpha <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">)</span><span class="token operator">**</span>gamma <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>pt<span class="token punctuation">)</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="infonce" tabindex="-1"><a class="header-anchor" href="#infonce" aria-hidden="true">#</a> infoNCE</h3><p>公式如下：</p><img title="" src="`+z+'" alt="" width="235" data-align="center">',8),os=s("p",null,[a("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"z"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"z_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("是一个样本的表示，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"z"),s("mo",null,"+")])]),s("annotation",{encoding:"application/x-tex"},"z_+")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6389em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2583em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mbin mtight"},"+")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])])])])]),a("是与"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"z"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"z_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("正相关的样本表示（通常称为正样本），"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"z"),s("mi",null,"j")])]),s("annotation",{encoding:"application/x-tex"},"z_j")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),a("是其他样本表示（可以是正样本也可以是负样本），"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"m"),s("mo",{stretchy:"false"},"("),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"sim()")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mord mathnormal"},"im"),s("span",{class:"mopen"},"("),s("span",{class:"mclose"},")")])])]),a("是相似度函数，通常是点积或余弦相似度，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"τ")]),s("annotation",{encoding:"application/x-tex"},"\\tau")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ")])])]),a("是温度参数，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N")]),s("annotation",{encoding:"application/x-tex"},"N")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N")])])]),a("是样本总数")],-1),ms=n("<p>温度系数的作用：</p><ol><li><p>控制分布的平滑度：</p><ul><li>较小的温度参数会使分布更加尖锐，模型会更加关注与正样本相似度高的样本，加大它们之间的区分度。</li><li>较大的温度参数会使分布更加平滑，模型对不同样本的区分度相对较小。</li></ul></li><li><p>影响训练的稳定性和收敛速度：</p><ul><li>不合适的温度参数可能导致训练不稳定或收敛缓慢。</li></ul></li></ol><p>温度系数调整策略：</p><ol><li><p>初始探索：</p><ul><li>可以在一个较大的范围内（如[0.01, 1]）尝试不同的温度参数值，观察模型的训练效果。</li><li>可以从中间值（如0.5）开始，逐步增大或减小来观察模型的性能变化。</li></ul></li><li><p>基于验证集调整：</p><ul><li>将数据集分为训练集和验证集。</li><li>在训练过程中，定期在验证集上评估模型性能，尝试不同的温度参数值，选择在验证集上表现最好的参数值。</li></ul></li><li><p>考虑任务特点：</p><ul><li>对于复杂的任务或数据分布比较分散的情况，可能需要较大的温度参数来使模型更加关注全局信息。</li><li>对于相对简单的任务或数据分布比较集中的情况，较小的温度参数可能更合适。</li></ul></li><li><p>结合其他超参数调整：</p><ul><li>温度参数的调整通常需要与其他超参数（如学习率、批次大小等）一起考虑，以找到最佳的组合。</li></ul></li></ol>",4);function rs(us,hs){const t=e("ExternalLinkIcon");return p(),i("div",null,[L,N,P,Q,q,T,K,D,H,R,j,O,B,S,C,F,E,G,I,V,X,A,J,U,W,Y,Z,$,ss,as,ns,ts,ls,es,s("p",null,[s("a",ps,[a("【深度学习 | 计算机视觉】Focal Loss原理及其实践（含源代码）-CSDN博客"),c(t)])]),is,cs,os,ms])}const gs=l(M,[["render",rs],["__file","machine_learning.html.vue"]]);export{gs as default};
