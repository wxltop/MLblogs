import{_ as o,r as t,o as r,c as a,a as e,b as d,d as c,e as s}from"./app-aa9cafec.js";const i={},p={class:"custom-container info"},l=e("svg",{xmlns:"http://www.w3.org/2000/svg","xmlns:xlink":"http://www.w3.org/1999/xlink",viewBox:"0 0 24 24"},[e("g",{fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[e("circle",{cx:"12",cy:"12",r:"9"}),e("path",{d:"M12 8h.01"}),e("path",{d:"M11 12h1v4h1"})])],-1),h=e("p",{class:"custom-container-title"},"INFO",-1),_={href:"https://zhuanlan.zhihu.com/p/56542707",target:"_blank",rel:"noopener noreferrer"},m=e("p",null,"《深度学习推荐系统》王喆",-1),v=s('<p>word2vec是将序列数据（如文本）转换为embeddings的方法，但是互联网数据一般都是网络结构，直接将word2vec用过来可能效果不佳，如Item2vec。所以有一些针对互联网的网络结构数据的embeddings方法出现。</p><h2 id="deepwalk" tabindex="-1"><a class="header-anchor" href="#deepwalk" aria-hidden="true">#</a> DeepWalk</h2><p>DeepWalk利用在图中随机游走，生成节点序列，将节点序列再传给skip-gram模型训练，就可以得到节点的embeddings。</p><p>为什么要这样做？</p><p>word2vec其实是学习单词的上下文，根据单词和单词之间的上下文关联来学习其表示。但是放到图结构数据中，“上下文”其实就可以替换为“周围的节点”，但是如果数据量过大，周围的节点可能很多，所以通过随机游走的方式来采样节点，行成一个个“上下文”（路径），将其输送给网络来学习节点和其他节点之间的关系，进而形成节点的表征。</p><p>如果是有向赋权图，那么随机游走会根据权值决定游走方向的概率，权值越大，选择该方向的可能性越大。</p><p>DeepWalk是DFS的方式遍历，还有一种BFS遍历的算法LINE。</p><h2 id="node2vec" tabindex="-1"><a class="header-anchor" href="#node2vec" aria-hidden="true">#</a> Node2vec</h2><p>node2vec是一种综合考虑DFS邻域和BFS邻域的graph embedding方法。简单来说，可以看作是deepwalk的一种扩展，是结合了DFS和BFS随机游走的deepwalk。</p><p>node2vec更能体现网路的同质性和结构性，同质性指的是距离相近节点的embeddings相似；结构性指的是结构上相似的节点的embeddings相似。</p><p>在互联网中，网络的同质性和结构性有直观的解释。<strong>同质性相同的物品很可能是同品类，很可能被经常同时购买</strong>；<strong>结构性相同的物品很可能是各品类的爆款，拥有类似的趋势</strong>。</p>',11);function g(k,u){const n=t("ExternalLinkIcon");return r(),a("div",null,[e("div",p,[l,h,e("p",null,[e("a",_,[d("【Graph Embedding】node2vec：算法原理，实现和应用 - 知乎 (zhihu.com)"),c(n)])]),m]),v])}const x=o(i,[["render",g],["__file","node2vec.html.vue"]]);export{x as default};
