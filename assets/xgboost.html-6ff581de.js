import{_ as e,r,o as c,c as a,a as o,b as s,d as n,e as p}from"./app-aa9cafec.js";const i="/MLblogs/assets/2024-04-11-22-37-40-image-7a034486.png",l={},h={class:"custom-container info"},_=o("svg",{xmlns:"http://www.w3.org/2000/svg","xmlns:xlink":"http://www.w3.org/1999/xlink",viewBox:"0 0 24 24"},[o("g",{fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[o("circle",{cx:"12",cy:"12",r:"9"}),o("path",{d:"M12 8h.01"}),o("path",{d:"M11 12h1v4h1"})])],-1),g=o("p",{class:"custom-container-title"},"INFO",-1),u={href:"https://zhuanlan.zhihu.com/p/162001079",target:"_blank",rel:"noopener noreferrer"},d={href:"https://zhuanlan.zhihu.com/p/562983875",target:"_blank",rel:"noopener noreferrer"},B=p('<p>梯度提升决策树（Gradient Boosting Decision Tree，GBDT）是一种基于boosting集成思想的加法模型，训练时采用前向分布算法进行贪婪的学习，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。</p><p>XGBoost的基本思想和GBDT相同，但XGBoost进行许多优化。</p><img src="'+i+'" title="" alt="" data-align="center"><p>GBDT利用梯度下降法求参，对GBDT的目标函数（损失函数）进行求导，拟合得到损失函数的一阶导数。因为损失函数只有一个变量，所以这个导数其实就是负梯度，通过这个导数进行更新参数</p><p><strong>关键的地方</strong>来了：凑巧的是，当loss function为<strong>square error loss</strong>时，loss function 的一阶导数就等于残差（y_true - y_pred）。所以这个时候能说，<strong>GBDT的负梯度这个时候就是在残差，即GBDT直接在拟合残差</strong></p><p>总结：如果loss function不是square error loss，GBDT不能够说是在拟合残差，只能怪说是利用负梯度求解（梯度下降法）。只是凑巧的是，当loss funtion是square error loss，负梯度恰好就是残差</p><p>GBDT和XGboost区别：</p><p>1、GBDT使用梯度下降法，所以只有一次导；XGboost使用牛顿法，使用到了loss function的二次导</p><p>xgboost如何分裂节点?</p><p>贪心算法，简单来说，就是保证每一步都是最优解，从而达到全局最优解的方法。放到决策树的生成中，就是：保证每一次结点的分裂产生的新的树，都是目标函数值最小的。</p><p><strong>那如何判断是否应该分裂这个节点呢？</strong></p><p>与传统决策树的判断依据一样——增益。只有当将这个结点分裂后，形成的新的树的目标函数值比之前的小，才分裂。换句话说，就是分裂后的树一定要比分裂前的树，目标函数更小。解释：如果当前结点A要分裂成B和C，<strong>原先A结点</strong>的目标函数值，<strong>减去</strong>B和C部分的目标函数值的和。如果大于0，则代表分裂有益，可以分裂。</p><p>缺失值如何处理？</p><p>对于第k个特征，我们首先将样本中第k个特征的特征值为缺失值的样本全部剔除。然后我们正常进行样本划分。最后，我们做两个假设，一个是缺失值全部摆左子结点，一个是摆右子节点。哪一个得到的增益大，就代表这个特征最好的划分。总结一下，就是缺失值都摆一起，选最好的情况</p>',14);function m(f,G){const t=r("ExternalLinkIcon");return c(),a("div",null,[o("div",h,[_,g,o("p",null,[o("a",u,[s("XGBoost的原理、公式推导、Python实现和应用 - 知乎 (zhihu.com)"),n(t)])]),o("p",null,[o("a",d,[s("超详细解析XGBoost（你想要的都有） - 知乎 (zhihu.com)"),n(t)])])]),B])}const k=e(l,[["render",m],["__file","xgboost.html.vue"]]);export{k as default};
