import{_ as s,r as a,o as g,c as i,a as t,b as o,d as n,e}from"./app-aa9cafec.js";const c="/MLblogs/assets/2024-02-20-18-35-22-image-1d3f3c07.png",l={},h={class:"custom-container info"},p=t("svg",{xmlns:"http://www.w3.org/2000/svg","xmlns:xlink":"http://www.w3.org/1999/xlink",viewBox:"0 0 24 24"},[t("g",{fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[t("circle",{cx:"12",cy:"12",r:"9"}),t("path",{d:"M12 8h.01"}),t("path",{d:"M11 12h1v4h1"})])],-1),d=t("p",{class:"custom-container-title"},"INFO",-1),u={href:"https://guangzhengli.com/blog/zh/vector-database/",target:"_blank",rel:"noopener noreferrer"},b={href:"https://www.bilibili.com/video/BV11a4y1c7SW/?vd_source=29624dbb703a504c9a36c90ccf9558d4",target:"_blank",rel:"noopener noreferrer"},_=e('<h2 id="gpt的对话记忆功能" tabindex="-1"><a class="header-anchor" href="#gpt的对话记忆功能" aria-hidden="true">#</a> GPT的对话记忆功能</h2><p>GPT 作为 LLM 模型是没有记忆功能的，所谓的记忆功能只是开发者将<strong>对话记录</strong>存储在<strong>内存或者数据库</strong>中，当你发送消息给 gpt 模型时，程序会自动将最近的几次对话记录（基于对话的字数限制在 4096 tokens 内）通过 prompt 组合成<strong>最终的问题，并发送给 ChatGPT</strong>。简而言之，如果你的对话记忆超过了 4096 tokens，那么它就会忘记之前的对话。</p><p>这是GPT的限制。</p><h2 id="向量数据库" tabindex="-1"><a class="header-anchor" href="#向量数据库" aria-hidden="true">#</a> 向量数据库</h2><p>向量数据库是解决上述限制的方法之一。向量数据库的核心思想是<strong>将文本转换成向量</strong>，然后将<strong>向量存储在数据库</strong>中，当用户输入问题时，将<strong>问题转换成向量</strong>，然后在<strong>数据库中搜索最相似的向量</strong>和上下文，最后<strong>将文本返回给用户</strong>。</p><p>比如有一份文档需要 GPT 处理，可以先<strong>将文档的所有内容转化成向量</strong>（这个过程称之为 Vector Embedding），然后当<strong>用户提出相关问题</strong>时，我们将用户的搜索内容<strong>转换成向量</strong>，然后在数据库中<strong>搜索最相似的向量</strong>，<strong>匹配最相似的几个上下文</strong>，最后将<strong>上下文返回给 GPT</strong>。这样不仅可以大大<strong>减少 GPT 的计算量</strong>，从而<strong>提高响应速度</strong>，更重要的是<strong>降低成本</strong>，并绕过 GPT 的 <strong>tokens 限制</strong>。</p><p>比如和 ChatGPT 之间有一份很长的对话，可以将所有对话以向量的方式保存起来，当我们提问给 ChatGPT 时，我们可以将问题转化为向量对过去所有的聊天记录进行语义搜索，找到与当前问题最相关的‘记忆’，一起提示给 ChatGPT，极大的提高 GPT 的输出质量。</p>',7),m=t("strong",null,"获得理解和维护长期记忆",-1),k={href:"https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fjs.langchain.com%2Fdocs%2F&source=article&objectId=2312534",target:"_blank",rel:"noopener noreferrer"},f={href:"https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fgithub.com%2Fguangzhengli%2Fvectorhub&source=article&objectId=2312534",target:"_blank",rel:"noopener noreferrer"},F={href:"https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fgithub.com%2Fguangzhengli%2FChatFiles&source=article&objectId=2312534",target:"_blank",rel:"noopener noreferrer"},x=e('<h2 id="vector-embeddings" tabindex="-1"><a class="header-anchor" href="#vector-embeddings" aria-hidden="true">#</a> vector embeddings</h2><p>传统数据库，搜索功能都是基于不同的索引方式（B Tree、倒排索引等）加上精确匹配和排序算法（BM25、TF-IDF）等实现的。本质还是<strong>基于文本的精确匹配</strong>，这种索引和搜索算法对于关键字的搜索功能非常合适，但对于<strong>语义搜索功能</strong>就非常弱。</p><p>例如，搜索“小狗”，只能得到带有“小狗”关键字相关的结果，无法得到“柯基”、“金毛”等结果，因为“小狗”和“金毛”是不同的词，<strong>传统数据库无法识别它们的语义关系</strong>，所以传统的应用需要人为的将“小狗”和“金毛”等词之间打上<strong>特征标签进行关联</strong>，这样才能实现语义搜索。而如何生成和挑选特征这个过程，也被称为 Feature Engineering (特征工程)，它是将原始数据转化成更好的表达问题本质的特征的过程。</p><p>但是如果处理非结构化的数据，会发现<strong>非结构化数据的特征数量会开始快速膨胀</strong>，例如我们处理的是图像、音频、视频等数据，这个过程就变得非常困难。例如，对于图像，可以标注颜色、形状、纹理、边缘、对象、场景等特征，但是这些特征太多了，而且很难人为的进行标注，所以需要一种<strong>自动化的方式来提取这些特征</strong>，而这可以通过 Vector Embedding 实现。</p><p>Vector Embedding 是由 AI 模型（例如大型语言模型 LLM）生成的，它会根据不同的算法生成高维度的向量数据，代表着数据的不同特征，这些特征代表了数据的不同维度。例如，对于文本，这些特征可能包括词汇、语法、语义、情感、情绪、主题、上下文等。对于音频，这些特征可能包括音调、节奏、音高、音色、音量、语音、音乐等。</p><p>文本向量可以通过 OpenAI 的 text-embedding-ada-002 模型生成，图像向量可以通过 clip-vit-base-patch32 模型生成，而音频向量可以通过 wav2vec2-base-960h 模型生成。</p><h2 id="相似性搜索-similarity-search" tabindex="-1"><a class="header-anchor" href="#相似性搜索-similarity-search" aria-hidden="true">#</a> 相似性搜索 (Similarity Search)</h2><p>想要在一个海量的数据中找到和某个向量最相似的向量，需要对数据库中的每个向量进行一次比较计算（最近邻算法），但这样的计算量是非常巨大的，所以需要一种高效的算法来解决这个问题。</p><p>高效的搜索算法有很多，其主要思想是通过两种方式提高搜索效率：</p><ol><li><p>减少向量大小——通过<strong>降维</strong>或减少表示向量值的长度。</p></li><li><p>缩小搜索范围——可以通过<strong>聚类</strong>或将向量组织成<strong>基于树形、图形结构来实现</strong>，并限制搜索范围仅在最接近的簇中进行，或者通过最相似的分支进行过滤。</p></li></ol><h3 id="k-means" tabindex="-1"><a class="header-anchor" href="#k-means" aria-hidden="true">#</a> K-Means</h3><p>保存向量数据后，先对向量数据先进行聚类。每次搜索时，只需要先判断搜索向量属于哪个簇，然后再在这一个簇中进行搜索，大大减少了搜索的范围。（有的时候可能遇到<strong>点遗漏</strong>的情况，此时可以<strong>增加聚类中心</strong>来解决）</p><blockquote><p>K-Means算法步骤：</p><ol><li>选择 k 个初始聚类中心。</li><li>将每个数据点分配到最近的聚类中心。</li><li>计算每个聚类的新中心。</li><li>重复步骤 2 和 3，直到聚类中心不再改变或达到最大迭代次数。</li></ol></blockquote><p>除了暴力搜索能完美的搜索出最相邻，所有的搜索算法只能在速度和质量还有内存上做一个权衡，这些算法也被称为<strong>近似最相邻</strong>（Approximate Nearest Neighbor）。</p><blockquote><p><strong>维度灾难</strong>: 随着维度增加，分类器性能提升；维度增加到某值后，分类器性能下降</p><p>在高维坐标系中，还会遇到维度灾难问题，具体来说，随着维度的增加，<strong>数据点之间的距离会呈指数级增长</strong>，这也就意味着，在高维坐标系中，需要更多的聚类中心点将数据点分成更小的簇，才能提高分类的质量。否者，向量和自己的聚类中心距离很远，会极大的降低搜索的速度和质量。</p><p>如果想要维持分类和搜索质量，就需要维护<strong>数量庞大的聚类中心</strong>。随之而来会带来另一个问题，那就是聚类中心点的数量会随着维度的增加而指数级增长，这样会导致我们存储码本的数量极速增加，从而极大的<strong>增加了内存的消耗</strong>。例如一个 128 维的向量，需要维护 2^64 个聚类中心才能维持不错的量化结果，但这样的码本存储大小已经超过维护原始向量的内存大小了。</p></blockquote><h3 id="faiss" tabindex="-1"><a class="header-anchor" href="#faiss" aria-hidden="true">#</a> Faiss</h3>',16),P={href:"https://zhuanlan.zhihu.com/p/432317877",target:"_blank",rel:"noopener noreferrer"},v=e('<p>Faiss是Facebook AI团队开源的<strong>针对聚类和相似性搜索</strong>库，为<strong>稠密向量</strong>提供<strong>高效相似度搜索</strong>和<strong>聚类</strong>，支持<strong>十亿级别</strong>向量的搜索，是目前最为成熟的近似近邻搜索库。它包含多种搜索任意大小向量集（向量集大小由RAM内存决定）的算法，以及用于算法评估和参数调整的支持代码。Faiss用C++编写，并提供与Numpy完美衔接的Python接口。除此以外，对一些核心算法提供了GPU实现。</p><p>Faiss中提供了若干种方法实现<strong>数据压缩</strong>，包括<strong>PCA</strong>、<strong>Product-Quantization(乘积量化)</strong> 等向量压缩的方法。</p><p>Faiss的核心原理其实就两个部分：</p><ol><li>Product Quantizer, 简称PQ.</li><li>Inverted File System, 简称IVF.</li></ol><blockquote><p><strong>Product Quantizer</strong></p><p>矢量量化方法，即vector quantization，其具体定义为: 将向量空间的点用一个<strong>有限子集来进行编码</strong>的过程。常见的聚类算法，都是一种矢量量化方法（量化为几个聚类中心）。而在ANN(Approximate Nearest Neighbor,近似最近邻) 搜索问题中，向量量化方法又以<strong>乘积量化</strong>(PQ, Product Quantization)最为典型。</p><p>PQ有一个<strong>Pre-train</strong>的过程，一般分为两步操作，第一步<strong>Cluster</strong>，第二步<strong>Assign</strong>。<strong>Cluster过程</strong>：假设向量维度D=128，将向量切分为M=4份，聚类中心K=256。将每一份的Nx32的向量拿来聚类为256个簇心，这样得到了Mx256个聚类中心。<strong>Assign过程</strong>：前面将向量切成M段，然后对于每一段向量，都可以找到对应的最近的簇心 ID，M段向量就对应了M个簇心 ID，<strong>一个128维的向量就变成了一个由M个ID组成的向量</strong>，这样就可以完成了Assign操作的过程。</p><p>现在，128维向量变成了M维，每个位置都只能取0~255（一共256个簇心），这就完成了向量的压缩。</p><img src="'+c+'" title="" alt="" data-align="center"><p>接下来是PQ的查询过程（向量检索）。</p></blockquote>',5);function A(I,M){const r=a("ExternalLinkIcon");return g(),i("div",null,[t("div",h,[p,d,t("p",null,[t("a",u,[o("向量数据库 (guangzhengli.com)"),n(r)])]),t("p",null,[t("a",b,[o("【上集】向量数据库技术鉴赏_哔哩哔哩_bilibili"),n(r)])])]),_,t("p",null,[o("向量数据库的火爆，正是因为它对于 AI "),m,o("以执行复杂任务时有非常大的帮助。例如可以试试 "),t("a",k,[o("LangChainJs 的文档搜索/Q&A 功能"),n(r)]),o(" 感受它的魅力，或者可以试试项目 "),t("a",f,[o("VectorHub"),n(r)]),o(" 和 "),t("a",F,[o("ChatFiles"),n(r)]),o("，可以上传一份文档或者基于一份网页文档，然后询问文档相关问题。这些功能都是基于 Vector Embedding 和向量数据库的产品。")]),x,t("p",null,[t("a",P,[o("搜索召回 | Facebook: 亿级向量相似度检索库Faiss原理+应用 - 知乎 (zhihu.com)"),n(r)])]),v])}const w=s(l,[["render",A],["__file","xiangliangshujuku.html.vue"]]);export{w as default};
