const e=JSON.parse('{"key":"v-38e20f31","path":"/docs/transformer/links.html","title":"transformer","lang":"en-US","frontmatter":{"title":"transformer","date":"2023/7/29","categories":["transformer"],"tags":["transformer"]},"headers":[{"level":2,"title":"Transformer为什么仅依靠一个「简单的预测损失」就能从梯度训练动态中涌现出高效的表征","slug":"transformer为什么仅依靠一个「简单的预测损失」就能从梯度训练动态中涌现出高效的表征","link":"#transformer为什么仅依靠一个「简单的预测损失」就能从梯度训练动态中涌现出高效的表征","children":[]},{"level":2,"title":"CVPR 2023 | 即插即用！SQR：对于训练DETR-family目标检测的探索和思考","slug":"cvpr-2023-即插即用-sqr-对于训练detr-family目标检测的探索和思考","link":"#cvpr-2023-即插即用-sqr-对于训练detr-family目标检测的探索和思考","children":[]},{"level":2,"title":"比Transformer快4成！Meta发布全新Megabyte模型","slug":"比transformer快4成-meta发布全新megabyte模型","link":"#比transformer快4成-meta发布全新megabyte模型","children":[]},{"level":2,"title":"比标准Attention提速5-9倍，大模型都在用的FlashAttention v2来了","slug":"比标准attention提速5-9倍-大模型都在用的flashattention-v2来了","link":"#比标准attention提速5-9倍-大模型都在用的flashattention-v2来了","children":[]},{"level":2,"title":"EfficientViT：让ViT更高效部署实现实时推理（附源码）","slug":"efficientvit-让vit更高效部署实现实时推理-附源码","link":"#efficientvit-让vit更高效部署实现实时推理-附源码","children":[]},{"level":2,"title":"超强Trick | 如何设计一个比Transformer更强的CNN Backbone","slug":"超强trick-如何设计一个比transformer更强的cnn-backbone","link":"#超强trick-如何设计一个比transformer更强的cnn-backbone","children":[]},{"level":2,"title":"transformer的细节到底是怎么样的？Transformer 连环18问！","slug":"transformer的细节到底是怎么样的-transformer-连环18问","link":"#transformer的细节到底是怎么样的-transformer-连环18问","children":[]},{"level":2,"title":"DETR解析第一部分：Detection Transformer的介绍","slug":"detr解析第一部分-detection-transformer的介绍","link":"#detr解析第一部分-detection-transformer的介绍","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"filePathRelative":"docs/transformer/links.md"}');export{e as data};
