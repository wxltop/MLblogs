import{_ as s,o as a,c as e,a as n,e as t}from"./app-aa9cafec.js";const p={},o=n("div",{class:"custom-container info"},[n("svg",{xmlns:"http://www.w3.org/2000/svg","xmlns:xlink":"http://www.w3.org/1999/xlink",viewBox:"0 0 24 24"},[n("g",{fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[n("circle",{cx:"12",cy:"12",r:"9"}),n("path",{d:"M12 8h.01"}),n("path",{d:"M11 12h1v4h1"})])]),n("p",{class:"custom-container-title"},"INFO"),n("p",null,"有许多内容取自ChatGPT.")],-1),c=t(`<h2 id="如何复现实验结果" tabindex="-1"><a class="header-anchor" href="#如何复现实验结果" aria-hidden="true">#</a> 如何复现实验结果</h2><p>要确保在每次相同的实验配置下能够复现实验结果，你需要注意以下几点：</p><ol><li><p><strong>随机种子（Random Seed）的设置：</strong> 在你的深度学习代码中，确保设置随机数生成器的种子。这将使得每次运行实验时生成的随机数序列是一样的，从而确保实验的随机性是可控的。在使用框架如PyTorch、TensorFlow时，你可以通过设置相应的随机种子参数来实现这一点。</p></li><li><p><strong>环境复制和管理：</strong> 创建一个虚拟环境（如使用Python的virtualenv或Anaconda环境），并记录环境中使用的库、依赖和版本。这样可以确保每次实验使用相同的软件环境，避免由于库版本不一致而导致的结果差异。</p></li><li><p><strong>数据处理和加载：</strong> 如果实验涉及数据处理步骤，确保每次数据加载和处理的流程都是一样的。这可以通过设置随机数据增强的参数、数据加载的顺序等来实现。</p></li><li><p><strong>模型架构和参数：</strong> 在实验中使用明确的模型架构和超参数设置，并在代码中进行清晰的记录。这样，每次运行实验时都可以确保使用相同的模型配置。</p></li><li><p><strong>日志记录：</strong> 在实验中添加详细的日志记录，包括模型结构、超参数、训练过程中的指标等。这有助于追踪和复现实验结果。</p></li><li><p><strong>版本控制：</strong> 使用版本控制系统（如Git）来管理你的代码。每次实验配置的更改都可以在版本控制中进行记录，以便随时回溯到特定的配置和代码状态。</p></li><li><p><strong>硬件和环境设置：</strong> 如果你使用了GPU或其他硬件加速，确保在每次实验中使用相同的硬件配置。另外，注意操作系统和其他系统设置也可能会影响实验结果，尽量保持这些设置的一致性。</p></li><li><p><strong>备份和文档：</strong> 定期备份你的实验代码、数据和结果。同时，为你的实验创建清晰的文档，记录每个实验的目的、配置、步骤和结果，以便将来能够轻松地复现实验。</p></li></ol><p>通过以上这些方法，你可以确保在每次相同的实验配置下都能够复现实验结果，从而提高实验的可重复性和可靠性。</p><h2 id="分布式-ddp-训练设置随机种子" tabindex="-1"><a class="header-anchor" href="#分布式-ddp-训练设置随机种子" aria-hidden="true">#</a> 分布式(DDP)训练设置随机种子</h2><p>当进行分布式训练（例如使用PyTorch的分布式数据并行，DDP）时，确保在每个进程中设置相同的随机种子非常重要，以确保实验的可复现性。先在train文件里加入setSeed()函数：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn <span class="token keyword">as</span> cudnn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> random

<span class="token keyword">import</span> os


<span class="token keyword">def</span> <span class="token function">setSeed</span><span class="token punctuation">(</span>myseed<span class="token punctuation">)</span><span class="token punctuation">:</span>
    cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>
    cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>
    cudnn<span class="token punctuation">.</span>fastest <span class="token operator">=</span> <span class="token boolean">False</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>
    <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>
    
    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&#39;PYTHONHASHSEED&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>exp<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> exp<span class="token punctuation">.</span>seed <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        setSeed<span class="token punctuation">(</span>exp<span class="token punctuation">.</span>seed<span class="token punctuation">)</span>
        warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span>
            <span class="token string">&quot;You have chosen to seed training. This will turn on the CUDNN deterministic setting, &quot;</span>
            <span class="token string">&quot;which can slow down your training considerably! You may see unexpected behavior &quot;</span>
            <span class="token string">&quot;when restarting from checkpoints.&quot;</span>
         <span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        cudnn<span class="token punctuation">.</span>fastest <span class="token operator">=</span> <span class="token boolean">True</span>
        cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span>
    
    trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>exp<span class="token punctuation">,</span> args<span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>除此之外，还需要为每一个epoch设置一个seed，如果有shuffle，保证不同次运行中shuffle后数据的顺序一样，有两种方式，第一种是：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 训练循环</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 在每个epoch前进行数据重置</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> epoch<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> batch_data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># 此处省略前向传播、损失计算和反向传播步骤</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>或者可以用的更高级点，如果重定义了sampler，先假设sampler内部有对数据索引的shuffle，然后在定义sampler的时候设置种子：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># fix the seed for reproducibility</span>
seed <span class="token operator">=</span> self<span class="token punctuation">.</span>seed <span class="token operator">+</span> get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>seed <span class="token keyword">else</span> <span class="token number">0</span> <span class="token operator">+</span> get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">worker_init_fn</span><span class="token punctuation">(</span>worker_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> worker_id<span class="token punctuation">)</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> worker_id<span class="token punctuation">)</span>

sampler <span class="token operator">=</span> InfiniteSampler<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>  <span class="token comment"># 这是自定义的Sampler</span>
batch_sampler_train <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>BatchSampler<span class="token punctuation">(</span>
                sampler<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> 

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> 
                          batch_sampler<span class="token operator">=</span>batch_sampler_train<span class="token punctuation">,</span> 
                          num_workers<span class="token operator">=</span>self<span class="token punctuation">.</span>data_num_workers<span class="token punctuation">,</span>
                          pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
                          worker_init_fn<span class="token operator">=</span>worker_init_fn<span class="token punctuation">)</span>  <span class="token comment"># 这里传入</span>

<span class="token keyword">return</span> train_loader
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这样设置了就不用每一次epoch的时候设置 <code>torch.manual_seed</code>。</p><p>对于第一段代码里，<code>setSeed</code>函数中的<code>cudnn.benchmark = False</code>是一个用于控制cuDNN库是否在每次前向传播时自动寻找最适合当前硬件的算法以提高性能的选项。设置为<code>True</code>时，cuDNN会根据当前硬件和输入数据的大小等信息，动态选择算法，从而在某些情况下可能获得更好的性能。</p><p>然而，在实现复现性的前提下，将<code>torch.backends.cudnn.benchmark</code>设置为<code>False</code>是更安全的做法。这是因为cuDNN库的自动调整可能会引入微小的性能变化，可能会导致在不同运行之间的结果不一致，从而影响实验的可复现性。设置为<code>False</code>会确保cuDNN使用固定的算法，从而在相同硬件和输入数据情况下获得一致的结果。</p><p>如果对性能优化特别关心，可以在实验的性能测试阶段将<code>torch.backends.cudnn.benchmark</code>设置为<code>True</code>，以找到最优的算法。然后在进行实验（消融实验）时，将其设置为<code>False</code>以确保结果的一致性和可复现性。</p><p>而<code>cudnn.fastest</code>是一个用于控制cuDNN库是否在最快速度上运行的选项。当你将<code>cudnn.fastest</code>设置为<code>True</code>时，cuDNN会尝试使用最快的算法，但这可能会牺牲一些准确性，因为它可能会选择不太稳定的算法。</p><p>与之前提到的<code>torch.backends.cudnn.benchmark</code>类似，如果你希望在性能测试阶段找到最优算法，可以将<code>cudnn.fastest</code>设置为<code>True</code>，以获取最快的训练速度。然而，在进行实验和研究时，为了确保结果的稳定性和可复现性，通常建议将<code>cudnn.fastest</code>设置为<code>False</code>。</p><h2 id="结果仍然不一样" tabindex="-1"><a class="header-anchor" href="#结果仍然不一样" aria-hidden="true">#</a> 结果仍然不一样？</h2><p>尽管在深度学习中设置随机种子可以增加实验的可复现性，但并不是所有情况下都能保证每次运行都会得到完全一样的结果。以下是一些可能导致结果不一致的情况：</p><ol><li><p><strong>平台和硬件差异：</strong> 即使设置了随机种子，不同的硬件平台（例如不同型号的GPU）或底层库（例如cuDNN版本）可能在数值计算和优化上存在微小的差异，导致结果不同。</p></li><li><p><strong>多线程并发：</strong> 在某些情况下，多线程并发操作可能会影响随机数生成的顺序，从而导致微小的差异。</p></li><li><p><strong>操作系统和环境：</strong> 不同操作系统和环境设置可能会影响随机数生成器的行为，导致结果不一致。</p></li><li><p><strong>数值精度：</strong> 深度学习中的计算涉及浮点数，由于不同计算机体系结构的浮点数精度可能存在微小差异，从而导致结果的微小差异。</p></li><li><p><strong>库的实现差异：</strong> 深度学习框架中不同的库实现在某些情况下可能存在微小的差异，例如数值计算的实现细节。</p></li><li><p><strong>优化算法的非确定性：</strong> 一些优化算法（例如随机梯度下降）可能会在每次迭代中使用不同的样本子集，从而导致微小的结果差异。</p></li></ol><p>尽管如此，通过合理设置随机种子、控制随机性以及遵循良好的实验配置和管理方法，你可以最大限度地提高实验的可复现性。在实际应用中，即使结果不完全一致，通常也会关注结果的趋势和一致性，而<strong>不是追求绝对相同的结果</strong>。</p>`,21),i=[o,c];function l(u,r){return a(),e("div",null,i)}const k=s(p,[["render",l],["__file","repeat_exp_results.html.vue"]]);export{k as default};
