import{_ as n,r as l,o as e,c as i,a as s,b as a,d as r,e as c}from"./app-aa9cafec.js";const m="/MLblogs/assets/2024-03-20-10-39-39-image-cb1139eb.png",o="/MLblogs/assets/2024-03-20-10-41-36-image-101072cc.png",p="/MLblogs/assets/2024-03-20-10-42-13-image-19451b0f.png",h="/MLblogs/assets/2024-03-20-10-47-44-image-505f385e.png",g={},u={class:"custom-container info"},d=s("svg",{xmlns:"http://www.w3.org/2000/svg","xmlns:xlink":"http://www.w3.org/1999/xlink",viewBox:"0 0 24 24"},[s("g",{fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[s("circle",{cx:"12",cy:"12",r:"9"}),s("path",{d:"M12 8h.01"}),s("path",{d:"M11 12h1v4h1"})])],-1),_=s("p",{class:"custom-container-title"},"INFO",-1),w={href:"https://zhuanlan.zhihu.com/p/67931198",target:"_blank",rel:"noopener noreferrer"},x=c('<h2 id="介绍" tabindex="-1"><a class="header-anchor" href="#介绍" aria-hidden="true">#</a> 介绍</h2><p>正则化是缓解过拟合的常用方法，正则化的方法通常是在代价函数多添加一项和模型权重有关的项：</p><img src="'+m+'" title="" alt="" data-align="center"><p>M是参数的个数，也是模型特征的维度，q是正则项的阶数。</p><p>考虑到在高维数据下很难给出正则项的几何意义，假设数据源只有两个特征：w1和w2，q在不同取值时，正则项的函数图像：</p><img src="'+o+'" title="" alt="" data-align="center"><p>不同函数值图像对应的等高线（俯视图）：</p><img src="'+p+'" title="" alt="" data-align="center"><h2 id="正则化有效的原因" tabindex="-1"><a class="header-anchor" href="#正则化有效的原因" aria-hidden="true">#</a> 正则化有效的原因</h2><ul><li><p>正则化旨在保留所有的特征，减少特征的权重值，确保所有特征对预测值都有少量的贡献。</p></li><li><p>当每个特征对预测值都有少量贡献时，这样模型可以良好的工作，这就是正则化的目的。</p></li></ul><p><strong>从几何意义的角度理解：</strong></p>',11),v=s("p",null,[a("最小化目标函数时，可以看做在控制损失函数不变的情况时令正则项最小化，几何意义如下所示：蓝色圈表示没有限制的损失函数随着 w 迭代寻找着最小化损失值的过程（同个圆上的损失函数值相同），"),s("strong",null,"蓝色圈和橙色圈之和就是目标函数值，目标函数最小化的点往往出现在蓝圈和橙圈相交的点即目标函数最小化的参数值"),a("  "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"w"),s("mo",null,"∗")])]),s("annotation",{encoding:"application/x-tex"},"w^*")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6887em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6887em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mbin mtight"},"∗")])])])])])])])])])]),a("。")],-1),b=s("img",{src:h,title:"",alt:"","data-align":"center"},null,-1),k=s("p",null,[a("可以看到，L1正则化的最优参数值 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"w"),s("mo",null,"∗")])]),s("annotation",{encoding:"application/x-tex"},"w^*")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6887em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6887em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mbin mtight"},"∗")])])])])])])])])])]),a(" 恰好是 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mn",null,"1")]),s("mo",null,"="),s("mn",null,"0")]),s("annotation",{encoding:"application/x-tex"},"w_1=0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0")])])]),a(" 的时候，意味着我们剔除了模型中一个特征（系数为0等价于剔除该特征），"),s("strong",null,"从而达到了降低模型复杂度的目的"),a("。在这个意义上L1正则化效果要优于L2正则化，"),s("strong",null,"但L1存在拐点不是处处可微，从而L2正则化有更好的求解特性"),a("。")],-1);function y(f,M){const t=l("ExternalLinkIcon");return e(),i("div",null,[s("div",u,[d,_,s("p",null,[s("a",w,[a("机器学习必知必会：正则化 - 知乎 (zhihu.com)"),r(t)])])]),x,v,b,k])}const L=n(g,[["render",y],["__file","regularization.html.vue"]]);export{L as default};
