import{_ as n,r as i,o as r,c as h,a as t,b as s,d as l,e as a}from"./app-aa9cafec.js";const d="/MLblogs/assets/2024-08-25-17-44-07-image-c8028bdd.png",m="/MLblogs/assets/2024-08-25-20-11-53-image-2fce6397.png",p="/MLblogs/assets/2024-09-01-19-08-48-image-d81305cb.png",c="/MLblogs/assets/2024-09-01-19-23-19-image-c91706d5.png",o="/MLblogs/assets/2024-09-01-16-05-17-image-ff8a7d35.png",g="/MLblogs/assets/2024-09-01-17-15-03-image-2731814b.png",u={},b=a('<h2 id="召回" tabindex="-1"><a class="header-anchor" href="#召回" aria-hidden="true">#</a> 召回</h2><p>召回现状：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>knn热门召回</td><td>基于C2维度多兴趣下的u2i召回（双塔）</td></tr><tr><td>非内积召回</td><td>u2i召回（单塔）</td></tr><tr><td>点击sku相关召回</td><td>i2i召回</td></tr><tr><td>点击source相关召回</td><td>重定向召回</td></tr><tr><td>点击sku相似召回</td><td>i2i召回</td></tr><tr><td>爆品冷启</td><td>冷启动召回</td></tr><tr><td>画像召回</td><td></td></tr></tbody></table><p>召回技术选型：</p><table><thead><tr><th>特点</th><th>具体描述</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>重recall，轻precision</td><td>使用相对简单朴素的方法召回扩量，把复杂计算给下游链路</td><td>召回逻辑简单，计算资源消耗少</td><td>难以把控召回质量，对下游泛化性要求非常高（SSB问题）</td></tr><tr><td>重precision，轻recall</td><td>使用复杂度较高的模型统一召回</td><td>对下游链路的泛化性要求低</td><td>召回整体量级小，难以满足较高的丰富性</td></tr><tr><td>二者折中</td><td></td><td></td><td></td></tr></tbody></table><p>召回线上评价指标：</p><table><thead><tr><th>方式</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>人工review</td><td>基于抽样的人工case review结论</td><td></td></tr><tr><td>全域hitrate</td><td>半离线、半在线指标</td><td>基于真实请求日志下全部召回结果整体的全域hiterate</td></tr><tr><td>端到端top20%流量sku数</td><td>马太指标</td><td>头部20%流量中，distinct商品数量</td></tr><tr><td>top 20uv覆盖率均值</td><td>马太指标</td><td>针对单个召回源维度的马太指标，单召回源维度头部20 uv覆盖的品的覆盖率均值</td></tr><tr><td>ucvr</td><td>效率指标</td><td>转化效率指标</td></tr><tr><td>人均推荐时长</td><td></td><td>点击效率指标</td></tr></tbody></table><p>粗排评价指标：</p><table><thead><tr><th>方式</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>端到端top20%流量sku数</td><td>马太指标</td><td></td></tr><tr><td>ucvr</td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h3 id="协同过滤" tabindex="-1"><a class="header-anchor" href="#协同过滤" aria-hidden="true">#</a> 协同过滤</h3><ul><li><p>基于用户的协同过滤算法（UserCF）：给用户推荐和他兴趣相似的其他用户喜欢的产品。</p></li><li><p>基于物品的协同过滤算法（ItemCF）：给用户推荐和他之前喜欢的物品相似的物品。</p></li><li><p>Swing：</p></li></ul><h3 id="基于向量的召回" tabindex="-1"><a class="header-anchor" href="#基于向量的召回" aria-hidden="true">#</a> 基于向量的召回</h3><h3 id="基于图的召回" tabindex="-1"><a class="header-anchor" href="#基于图的召回" aria-hidden="true">#</a> 基于图的召回</h3><h3 id="基于序列的召回" tabindex="-1"><a class="header-anchor" href="#基于序列的召回" aria-hidden="true">#</a> 基于序列的召回</h3><h2 id="排序" tabindex="-1"><a class="header-anchor" href="#排序" aria-hidden="true">#</a> 排序</h2><h3 id="多任务学习" tabindex="-1"><a class="header-anchor" href="#多任务学习" aria-hidden="true">#</a> 多任务学习</h3>',16),y={href:"https://datawhalechina.github.io/fun-rec/#/ch02/ch2.2/ch2.2.5/ESMM",target:"_blank",rel:"noopener noreferrer"},x=a('<h4 id="_1-mmoe" tabindex="-1"><a class="header-anchor" href="#_1-mmoe" aria-hidden="true">#</a> 1. MMOE</h4><p>解决的问题：多个任务共享一个bottom时，若任务之间相关性不大，一起学习会互相影响，导致最终都学不好。有几个任务就有几个gate，而不是所有任务都用一个gate</p><p>缺点：</p><ul><li>MMOE中所有的Expert是被所有任务所共享，这可能无法捕捉到任务之间更复杂的关系，从而给部分任务带来一定的噪声。</li><li>在复杂任务机制下，MMOE不同专家在不同任务的权重学的差不多</li><li>不同的Expert之间没有交互，联合优化的效果有所折扣</li></ul><p>MMOE容易出现的问题：极化现象</p><p>即某一个或某几个专家的权重为1，其他接近0</p><p>解决方案：对gate输出权重dropout</p><p>MOE和MMOE的区别：</p><p>MOE（Mixture of Experts）和 MMOE（Multi-gate Mixture-of-Experts）</p><ul><li><p>MOE由多个专家网络和一个门控网络组成。门控网络根据输入数据为每个专家分配一个权重，然后将所有专家的输出按照权重进行加权求和，得到最终的输出。<strong>这可能导致不同任务之间的冲突，特别是当任务之间的相关性较弱时。</strong></p></li><li><p>MMOE：在 MOE 的基础上进行了改进。它针对不同的任务设置了多个门控网络，每个门控网络可以根据特定任务的输入数据为专家网络分配不同的权重。<strong>每个门控网络可以根据特定任务的需求，有针对性地选择和组合专家的输出，从而提高模型在不同任务上的性能。</strong></p></li></ul><hr><h4 id="_2-esmm" tabindex="-1"><a class="header-anchor" href="#_2-esmm" aria-hidden="true">#</a> 2. ESMM</h4><p>解决的问题：</p><ul><li><p>样本选择偏差：cvr样本是{点击未转化，点击转化}，而实际上只要曝光了的样本都要预测其ctr和cvr，样本集合={曝光的样本}。构建的训练样本集相当于是从一个与真实分布不一致的分布中采样得到的，这一定程度上违背了机器学习中训练数据和测试数据独立同分布的假设。</p></li><li><p>训练数据稀疏（data sparsity，DS）：点击样本只占整个曝光样本的很小一部分，而转化样本又只占点击样本的很小一部分。如果只用点击后的数据训练CVR模型，可用的样本将极其稀疏。</p></li></ul><p>如何做的：</p><p>引入两个辅助任务CTR、CTCVR(已点击然后转化)</p>',16),f=t("div",{class:"custom-container info"},[t("svg",{xmlns:"http://www.w3.org/2000/svg","xmlns:xlink":"http://www.w3.org/1999/xlink",viewBox:"0 0 24 24"},[t("g",{fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[t("circle",{cx:"12",cy:"12",r:"9"}),t("path",{d:"M12 8h.01"}),t("path",{d:"M11 12h1v4h1"})])]),t("p",{class:"custom-container-title"},"INFO"),t("p",null,"注意：其中只有CTR和CVR的label都同时为1时，CTCVR的label才是正样本1。如果出现CTR=0，CVR=1的样本，则为不合法样本，需删除。 pCTCVR是指，当用户已经点击的前提下，用户会购买的概率；pCVR是指如果用户点击了，会购买的概率。")],-1),_=t("p",null,"模型结构：",-1),w=t("p",null,"主任务和辅助任务共享特征，不同任务输出层使用不同的网络，将cvr的预测值*ctr的预测值作为ctcvr任务的预测值，利用ctcvr和ctr的label构造损失函数。",-1),M=t("p",null,[t("strong",null,"pCVR 只是一个中间变量。而pCTCVR和pCTR的数据是在完整样本空间中提取的，从而相当于pCVR也是在整个曝光样本空间中建模"),s("。")],-1),v=t("img",{title:"",src:d,alt:"","data-align":"center",width:"427"},null,-1),P=t("hr",null,null,-1),T=t("h4",{id:"_3-ple",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#_3-ple","aria-hidden":"true"},"#"),s(" 3. PLE")],-1),N={href:"https://datawhalechina.github.io/fun-rec/#/ch02/ch2.2/ch2.2.5/PLE",target:"_blank",rel:"noopener noreferrer"},E=a('<p><strong>提出问题</strong>：</p><ul><li>负迁移（Negative Transfer）：针对相关性较差的任务，使用shared-bottom这种硬参数共享的机制会出现负迁移现象，<strong>不同任务之间存在冲突时，会导致模型无法有效进行参数的学习，不如对多个任务单独训练</strong>。</li><li>跷跷板现象（Seesaw Phenomenon）：针对相关性较为复杂的场景，通常不可避免出现跷跷板现象。多任务学习模式下，往往能够提升一部分任务的效果，但同时需要牺牲其他任务的效果。<strong>即无法实现任务的共赢</strong>。即使通过MMOE这种方式减轻负迁移现象，跷跷板问题仍然广泛存在。</li></ul><p><strong>解决问题</strong>：<strong>解决跷跷板现象</strong>，以及优化MMOE模型</p><p><strong>提出方案</strong>：定制门控。PLE将<strong>共享的部分</strong>和每个任务<strong>特定的部分</strong>显式的分开，强化任务自身独立特性。</p><p>PLE就是上述CGC网络的多层纵向叠加</p><img title="" src="'+m+'" alt="" width="388" data-align="center"><p><strong>vs MMOE</strong>：MMOE将所有Expert一视同仁，都加权输入到每一个任务的Tower，其中任务之间的关系完全交由gate自身进行学习</p><p><strong>Loss设计</strong>：不同任务有不同的样本空间，PLE将 全部任务样本空间 的 并集 作为 训练样本空间，分别针对每个任务算loss时，<strong>只考虑该任务的样本的空间</strong>，一般需对这种数据集会附带一个样本空间标签</p><hr><h4 id="其他" tabindex="-1"><a class="header-anchor" href="#其他" aria-hidden="true">#</a> 其他</h4><p>有些业务的依赖关系不止有曝光-点击-转化三层，后续的改进模型提出了更深层次的任务依赖关系建模。比如：</p><p>（1）阿里的ESMM2: 在点击到购买之前，用户还有可能产生加入购物车（Cart）、加入心愿单（Wish）等行为。</p><p>​ 相较于直接学习 click-&gt;buy (稀疏度约2.6%)，可以通过Action路径将目标分解，以Cart为例：click-&gt;cart (稀疏 度为10%)，cart-&gt;buy(稀疏度为12%)，通过分解路径，建立多任务学习模型来分步求解CVR模型，<strong>缓解稀疏问题</strong>，该模型同样也引入了特征共享机制。</p><p>（2）美团的AITM：信用卡业务中，用户转化通常是一个<strong>曝光-&gt;点击-&gt;申请-&gt;核卡-&gt;激活</strong>的过程，具有5层的链路。</p><h3 id="序列模型" tabindex="-1"><a class="header-anchor" href="#序列模型" aria-hidden="true">#</a> 序列模型</h3><h4 id="din" tabindex="-1"><a class="header-anchor" href="#din" aria-hidden="true">#</a> DIN</h4><p>DIN模型的创新点或者解决的问题就是<strong>使用了注意力机制来对用户的兴趣动态模拟</strong>，即解决用户动态变化的兴趣爱好</p><p>DIN中的activation unit结构如下，输入是用户某一时刻的行为特征和target item，中间做外积并展开与另外两个特征拼接，传给MLP和激活函数。外积的作用：更细粒度的考虑用户行为与target item的交互关系：</p><img title="" src="'+p+'" alt="" width="163" data-align="center"><p>DIN的缺点：关注短期兴趣，遗忘长期兴趣</p><h4 id="dien" tabindex="-1"><a class="header-anchor" href="#dien" aria-hidden="true">#</a> DIEN</h4><p>DIEN（Deep Interest Evolution Network）的主要动机是为了更有效地捕捉和利用用户兴趣的动态变化特性，以提升推荐系统的性能（更精细化的建模用户兴趣的演进过程）</p><p><strong>精确刻画用户兴趣变化</strong>：在电商等推荐场景中，用户的兴趣是不断变化的。例如，用户在不同时间段可能对不同类别的商品有不同的偏好，且这种兴趣的变化存在一定的序列依赖关系。</p><p>具体来说，DIEN 主要由兴趣抽取层和兴趣进化层组成：</p><ul><li><strong>兴趣抽取层</strong>：使用 GRU 对用户行为的依赖关系建模，输出每个时间步的隐藏状态作为用户兴趣的表示。并且引入辅助 loss，<strong>通过用下一个时间步的行为来监督学习当前时间步的兴趣状态，帮助 GRU 的隐状态更好地表达用户兴趣</strong>，解决了传统 GRU 在用户兴趣抽取中可能因长序列导致梯度反向传播不能很好作用到头部行为的问题，同时也能给 embedding 层的学习带来更多语义信息，学习到更好的 embedding 12。</li><li><strong>兴趣进化层</strong>：利用基于注意力机制的 GRU（如 AUGRU）来学习用户的兴趣演化。<strong>将target item的 embedding 向量与兴趣抽取层的输出隐向量交互生成注意力分数，并将其融入到 GRU 的更新门中，以控制 GRU 的隐层输出。这样可以使模型更关注与target item相关的兴趣演化轨迹，减弱不相关兴趣的干扰</strong>，有助于模拟相对目标项目的兴趣演化过程。</li></ul><h4 id="sim" tabindex="-1"><a class="header-anchor" href="#sim" aria-hidden="true">#</a> SIM</h4><p>SIM要解决的问题：解决DIN无法处理长期兴趣的问题（计算量大，且易遗忘）</p><p>效果：用SIM可以保留用户长期记录，n可以到达几千。如果不用SIM，n的大小一般在一两百。</p><p>做法简述：对于每一个target item，在用户的LastN个行为中做快速查找，找到k个相似商品，将LastN变为topk，然后输入到注意力层，故可以减少模型计算量（从n降为k）</p><p>详细描述：</p><ol><li><p>第一步：查找。</p><ul><li><p>方法1：Hard Search。基于规则的查找，比如根据物品的类目保留LastN中物品类目相同的。优点：快速，简单，无需训练</p></li><li><p>方法2：Soft Search。将target item和LastN物品转为embedding，将target item作为query做k近邻查找，保留最接近的k个。效果更好</p></li></ul></li><li><p>第二步：注意力。这一步本质和DIN没区别，区别在于历史行为从LastN变为了topk，为何去掉可以有用呢？因为若不去掉，那些不相关的item与target item的相关度也是接近0的，影响不大。</p></li></ol><img title="" src="'+c+'" alt="" width="511" data-align="center"><p>与DIN不同，SIM处理的是长期兴趣，而DIN处理的是短期的兴趣，可以不用时间特征，而SIM将时间离散化转为embedding与item embedding拼接，作为一个历史行为的embedding，这样效果更好。</p><h4 id="dsin" tabindex="-1"><a class="header-anchor" href="#dsin" aria-hidden="true">#</a> DSIN</h4><h3 id="特征交叉" tabindex="-1"><a class="header-anchor" href="#特征交叉" aria-hidden="true">#</a> 特征交叉</h3><h3 id="wide-deep系列" tabindex="-1"><a class="header-anchor" href="#wide-deep系列" aria-hidden="true">#</a> Wide&amp;Deep系列</h3><h2 id="评估指标" tabindex="-1"><a class="header-anchor" href="#评估指标" aria-hidden="true">#</a> 评估指标</h2><h3 id="precision" tabindex="-1"><a class="header-anchor" href="#precision" aria-hidden="true">#</a> precision</h3><p>对于正类样本的预测的准确率：</p>',39),k=t("p",null,[t("span",{class:"katex"},[t("span",{class:"katex-mathml"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("semantics",null,[t("mrow",null,[t("mtext",null,"precision"),t("mo",null,"="),t("mfrac",null,[t("mrow",null,[t("mi",null,"T"),t("mi",null,"P")]),t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"P")])])]),t("annotation",{encoding:"application/x-tex"},"\\text{precision}=\\frac{TP}{TP+FP}")])])]),t("span",{class:"katex-html","aria-hidden":"true"},[t("span",{class:"base"},[t("span",{class:"strut",style:{height:"0.8623em","vertical-align":"-0.1944em"}}),t("span",{class:"mord text"},[t("span",{class:"mord"},"precision")]),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),t("span",{class:"mrel"},"="),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),t("span",{class:"base"},[t("span",{class:"strut",style:{height:"1.2757em","vertical-align":"-0.4033em"}}),t("span",{class:"mord"},[t("span",{class:"mopen nulldelimiter"}),t("span",{class:"mfrac"},[t("span",{class:"vlist-t vlist-t2"},[t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.8723em"}},[t("span",{style:{top:"-2.655em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"FP")])])]),t("span",{style:{top:"-3.23em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),t("span",{style:{top:"-3.394em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP")])])])]),t("span",{class:"vlist-s"},"​")]),t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.4033em"}},[t("span")])])])]),t("span",{class:"mclose nulldelimiter"})])])])])],-1),C=t("h3",{id:"recall",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#recall","aria-hidden":"true"},"#"),s(" recall")],-1),R=t("p",null,"所有实际为正类的样本中，被正确预测为正例的比例：",-1),z=t("p",null,[t("span",{class:"katex"},[t("span",{class:"katex-mathml"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("semantics",null,[t("mrow",null,[t("mtext",null,"recall"),t("mo",null,"="),t("mfrac",null,[t("mrow",null,[t("mi",null,"T"),t("mi",null,"P")]),t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"N")])])]),t("annotation",{encoding:"application/x-tex"},"\\text{recall}=\\frac{TP}{TP+FN}")])])]),t("span",{class:"katex-html","aria-hidden":"true"},[t("span",{class:"base"},[t("span",{class:"strut",style:{height:"0.6944em"}}),t("span",{class:"mord text"},[t("span",{class:"mord"},"recall")]),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),t("span",{class:"mrel"},"="),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),t("span",{class:"base"},[t("span",{class:"strut",style:{height:"1.2757em","vertical-align":"-0.4033em"}}),t("span",{class:"mord"},[t("span",{class:"mopen nulldelimiter"}),t("span",{class:"mfrac"},[t("span",{class:"vlist-t vlist-t2"},[t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.8723em"}},[t("span",{style:{top:"-2.655em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"FN")])])]),t("span",{style:{top:"-3.23em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),t("span",{style:{top:"-3.394em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP")])])])]),t("span",{class:"vlist-s"},"​")]),t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.4033em"}},[t("span")])])])]),t("span",{class:"mclose nulldelimiter"})])])])])],-1),F=t("h3",{id:"auc",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#auc","aria-hidden":"true"},"#"),s(" AUC")],-1),L=t("p",null,"是ROC曲线下的面积，ROC曲线的纵轴是TPR，横轴是FPR，",-1),I=t("p",null,[t("span",{class:"katex"},[t("span",{class:"katex-mathml"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("semantics",null,[t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mi",null,"R"),t("mo",null,"="),t("mfrac",null,[t("mrow",null,[t("mi",null,"T"),t("mi",null,"P")]),t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"N")])])]),t("annotation",{encoding:"application/x-tex"},"TPR=\\frac{TP}{TP+FN}")])])]),t("span",{class:"katex-html","aria-hidden":"true"},[t("span",{class:"base"},[t("span",{class:"strut",style:{height:"0.6833em"}}),t("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"TPR"),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),t("span",{class:"mrel"},"="),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),t("span",{class:"base"},[t("span",{class:"strut",style:{height:"1.2757em","vertical-align":"-0.4033em"}}),t("span",{class:"mord"},[t("span",{class:"mopen nulldelimiter"}),t("span",{class:"mfrac"},[t("span",{class:"vlist-t vlist-t2"},[t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.8723em"}},[t("span",{style:{top:"-2.655em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"FN")])])]),t("span",{style:{top:"-3.23em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),t("span",{style:{top:"-3.394em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP")])])])]),t("span",{class:"vlist-s"},"​")]),t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.4033em"}},[t("span")])])])]),t("span",{class:"mclose nulldelimiter"})])])])])],-1),S=t("p",null,[t("span",{class:"katex"},[t("span",{class:"katex-mathml"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("semantics",null,[t("mrow",null,[t("mi",null,"F"),t("mi",null,"P"),t("mi",null,"R"),t("mo",null,"="),t("mfrac",null,[t("mrow",null,[t("mi",null,"F"),t("mi",null,"P")]),t("mrow",null,[t("mi",null,"F"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"T"),t("mi",null,"N")])])]),t("annotation",{encoding:"application/x-tex"},"FPR=\\frac{FP}{FP+TN}")])])]),t("span",{class:"katex-html","aria-hidden":"true"},[t("span",{class:"base"},[t("span",{class:"strut",style:{height:"0.6833em"}}),t("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"FPR"),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),t("span",{class:"mrel"},"="),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),t("span",{class:"base"},[t("span",{class:"strut",style:{height:"1.2757em","vertical-align":"-0.4033em"}}),t("span",{class:"mord"},[t("span",{class:"mopen nulldelimiter"}),t("span",{class:"mfrac"},[t("span",{class:"vlist-t vlist-t2"},[t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.8723em"}},[t("span",{style:{top:"-2.655em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"FP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"TN")])])]),t("span",{style:{top:"-3.23em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),t("span",{style:{top:"-3.394em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"FP")])])])]),t("span",{class:"vlist-s"},"​")]),t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.4033em"}},[t("span")])])])]),t("span",{class:"mclose nulldelimiter"})])])])])],-1),O=a('<p>AUC的物理含义：对正样本打分高于负样本的概率</p><h3 id="pr曲线" tabindex="-1"><a class="header-anchor" href="#pr曲线" aria-hidden="true">#</a> PR曲线</h3><p>纵轴是precision，横轴是recall，曲线下的面积是AP（average precision）越大，性能越好</p><h3 id="map" tabindex="-1"><a class="header-anchor" href="#map" aria-hidden="true">#</a> mAP</h3><p>AP是单个类别的平均精度，mAP是多个类别的平均AP值</p><h3 id="f1-score" tabindex="-1"><a class="header-anchor" href="#f1-score" aria-hidden="true">#</a> F1-score</h3><p>是precision和recall的调和平均数，综合考虑了二者，需要平衡二者时使用</p><h3 id="accuracy" tabindex="-1"><a class="header-anchor" href="#accuracy" aria-hidden="true">#</a> accuracy</h3><p>所有被正确预估的样本占总样本的比例，是衡量模型整体的预测能力：</p>',9),D=t("p",null,[t("span",{class:"katex"},[t("span",{class:"katex-mathml"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("semantics",null,[t("mrow",null,[t("mtext",null,"accuracy"),t("mo",null,"="),t("mfrac",null,[t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"T"),t("mi",null,"N")]),t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"T"),t("mi",null,"N"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"N")])])]),t("annotation",{encoding:"application/x-tex"},"\\text{accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}")])])]),t("span",{class:"katex-html","aria-hidden":"true"},[t("span",{class:"base"},[t("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),t("span",{class:"mord text"},[t("span",{class:"mord"},"accuracy")]),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),t("span",{class:"mrel"},"="),t("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),t("span",{class:"base"},[t("span",{class:"strut",style:{height:"1.2757em","vertical-align":"-0.4033em"}}),t("span",{class:"mord"},[t("span",{class:"mopen nulldelimiter"}),t("span",{class:"mfrac"},[t("span",{class:"vlist-t vlist-t2"},[t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.8723em"}},[t("span",{style:{top:"-2.655em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"TN"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"FP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"FN")])])]),t("span",{style:{top:"-3.23em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),t("span",{style:{top:"-3.394em"}},[t("span",{class:"pstrut",style:{height:"3em"}}),t("span",{class:"sizing reset-size6 size3 mtight"},[t("span",{class:"mord mtight"},[t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"TP"),t("span",{class:"mbin mtight"},"+"),t("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"TN")])])])]),t("span",{class:"vlist-s"},"​")]),t("span",{class:"vlist-r"},[t("span",{class:"vlist",style:{height:"0.4033em"}},[t("span")])])])]),t("span",{class:"mclose nulldelimiter"})])])])])],-1),V=a('<h3 id="ndcg" tabindex="-1"><a class="header-anchor" href="#ndcg" aria-hidden="true">#</a> NDCG</h3><p>可以有效地评估结果列表的质量，考虑了结果的相关性和位置</p><h2 id="常问问题" tabindex="-1"><a class="header-anchor" href="#常问问题" aria-hidden="true">#</a> 常问问题</h2><h3 id="推荐系统的链路" tabindex="-1"><a class="header-anchor" href="#推荐系统的链路" aria-hidden="true">#</a> 推荐系统的链路</h3><p>召回：多路召回源一起召回，每一路召回几十或几千，将数据量从亿级别-&gt;千级别。将各路召回的商品进行去重和过滤，过滤掉用户不喜欢的作者等</p><p>粗排：使用规模较小的机器学习模型对几千篇笔记打分，按照分数排序和截断，保留分数最高的几百个</p><p>精排：使用更加复杂的模型对item打分，通常精排会输出多个分数，如点击率、点赞率、收藏率、转发率，最后融合为一个分数，该分数反应用户的兴趣爱好，<strong>该阶段可以截断也可以不截断</strong></p><p>重排：带上精排的打分进入重排，根据精排的分数和多样性分数抽样（抽样有两个依据：多样性、精排分数），得到几十个，然后用规则打散相似内容，插入广告和运营内容</p><img src="'+o+'" title="" alt="" data-align="center"><p>粗排模型：交叉特征指的是用户和商品的交叉。用户塔可以做的很大，因为线上推理每个用户只需执行一遍，物品特征可以事先存好，故也可以做的较大，交叉塔不能提前存，会动态变化，有n个物品就要做n次推理，故交叉塔要很小。粗排模型大部分计算量在上层网络</p><img title="" src="'+g+'" alt="" data-align="center" width="557"><h3 id="多路召回结果是否需要去重" tabindex="-1"><a class="header-anchor" href="#多路召回结果是否需要去重" aria-hidden="true">#</a> 多路召回结果是否需要去重</h3><p>需要</p><ul><li><p>提升用户体验：避免重复展示。如果不同召回源的结果不进行去重，用户可能会在召回结果中看到大量重复的商品。这会给用户带来不好的体验，</p></li><li><p>减少计算资源浪费：不去重的话，后续的排序阶段需要对大量重复的商品进行处理，浪费计算资源和时间。</p></li><li><p>优化排序效果：重复的商品可能会在排序阶段占据多个位置，影响真正有价值的商品的排名。</p></li><li><p>满足业务需求：在某些业务场景中，可能有明确的要求不展示重复的商品。例如，在广告推荐中，广告主通常不希望自己的广告多次出现，以免引起用户的反感。</p></li></ul><h3 id="新增召回源" tabindex="-1"><a class="header-anchor" href="#新增召回源" aria-hidden="true">#</a> 新增召回源</h3><h3 id="离线hiterate" tabindex="-1"><a class="header-anchor" href="#离线hiterate" aria-hidden="true">#</a> 离线HiteRate</h3><p>若召回源离线hitrate效果好，能一定说明其线上效果会好吗？为什么？若离线hitrate效果差，线上效果一定差吗？为什么？</p><p>不一定。</p><ul><li><strong>数据差异</strong>：离线评估通常使用历史数据，这些数据可能无法完全代表<strong>线上的实时情况</strong>。<strong>线上环境中数据是动态变化的</strong>，用户的<strong>行为模式、兴趣偏好</strong>等可能随时间发生改变。例如，某些突发事件可能导致用户兴趣的突然转移，而离线数据无法捕捉到这些变化，使得基于离线数据训练和评估的召回源在面对线上新情况时表现不佳。</li></ul><h2 id="a-b测试" tabindex="-1"><a class="header-anchor" href="#a-b测试" aria-hidden="true">#</a> A/B测试</h2><p>如新增一路召回源，离线指标正向，但是线上不一定好。</p><p>下一步是做线上的小流量A/B测试，考察新的召回通道对线上指标的影响。</p><p>用户分桶：小流量测试时需要对用户分桶。</p><h3 id="point-wise-pair-wise-list-wise的区别" tabindex="-1"><a class="header-anchor" href="#point-wise-pair-wise-list-wise的区别" aria-hidden="true">#</a> point-wise, pair-wise, list-wise的区别</h3><h3 id="跷跷板问题" tabindex="-1"><a class="header-anchor" href="#跷跷板问题" aria-hidden="true">#</a> 跷跷板问题</h3><p>多任务中的跷跷板问题如何解决？</p><h3 id="给样本提权除了乘一个数还有没有更好的方法" tabindex="-1"><a class="header-anchor" href="#给样本提权除了乘一个数还有没有更好的方法" aria-hidden="true">#</a> 给样本提权除了乘一个数还有没有更好的方法</h3><h3 id="特征重要性分析" tabindex="-1"><a class="header-anchor" href="#特征重要性分析" aria-hidden="true">#</a> 特征重要性分析</h3><h3 id="dcn和senet的区别" tabindex="-1"><a class="header-anchor" href="#dcn和senet的区别" aria-hidden="true">#</a> DCN和SENet的区别</h3><h3 id="常见的特征交叉" tabindex="-1"><a class="header-anchor" href="#常见的特征交叉" aria-hidden="true">#</a> 常见的特征交叉</h3><h3 id="mmoe-vs-esmm" tabindex="-1"><a class="header-anchor" href="#mmoe-vs-esmm" aria-hidden="true">#</a> MMOE vs ESMM</h3><p>MMOE和ESMM是用来解决什么问题的？可以通过什么样的评估指标来判断该问题已经解决</p>',32);function A(U,G){const e=i("ExternalLinkIcon");return r(),h("div",null,[b,t("p",null,[t("a",y,[s("ESMM (datawhalechina.github.io)"),l(e)])]),x,f,_,w,M,v,P,T,t("p",null,[t("a",N,[s("PLE (datawhalechina.github.io)"),l(e)])]),E,k,C,R,z,F,L,I,S,O,D,V])}const H=n(u,[["render",A],["__file","recsys.html.vue"]]);export{H as default};
