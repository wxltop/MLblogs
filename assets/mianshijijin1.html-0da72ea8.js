import{_ as e,r,o as i,c as o,a as p,b as a,d as s,e as t}from"./app-aa9cafec.js";const l="/MLblogs/imgs/2023-08-08-15-37-57-image.png",h="/MLblogs/imgs/2023-08-08-15-39-54-image.png",g="/MLblogs/imgs/2023-08-08-15-40-17-image.png",c="/MLblogs/imgs/2023-08-08-15-40-33-image.png",d="/MLblogs/imgs/2023-08-08-15-40-53-image.png",m="/MLblogs/imgs/2023-08-08-15-41-09-image.png",u="/MLblogs/imgs/2023-08-08-15-41-21-image.png",b="/MLblogs/imgs/2023-08-08-15-41-39-image.png",_="/MLblogs/imgs/2023-08-08-15-41-51-image.png",f="/MLblogs/imgs/2023-08-08-15-42-06-image.png",T="/MLblogs/imgs/2023-08-08-15-42-21-image.png",x="/MLblogs/imgs/2023-08-08-15-42-41-image.png",B="/MLblogs/imgs/2023-08-08-15-42-51-image.png",L={},v=p("h2",{id:"算法工程师-nlp-搜索推荐-机器学习-常见面试题",tabindex:"-1"},[p("a",{class:"header-anchor",href:"#算法工程师-nlp-搜索推荐-机器学习-常见面试题","aria-hidden":"true"},"#"),a(" 算法工程师（NLP/搜索推荐/机器学习）常见面试题")],-1),P={href:"https://docs.qq.com/doc/DR0ZBbmNKc0l3RGR2",target:"_blank",rel:"noopener noreferrer"},y=t('<p>（b站/小红书/抖音：一只甜药，wb：炸酱子）</p><h3 id="svm原理" tabindex="-1"><a class="header-anchor" href="#svm原理" aria-hidden="true">#</a> SVM原理</h3><p>SVM是一个二分类算法，在空间里找一个超平面，将空间分为两块，其中某一类的点都在超平面上方，另一类都在超平面下方。</p><p>算法的原理是找一个超平面，使得两类的点中离平面最近的那个点离平面的距离最远。这个点称为支持向量，所以SVM的全名是支持向量机。</p><h3 id="lr逻辑回归" tabindex="-1"><a class="header-anchor" href="#lr逻辑回归" aria-hidden="true">#</a> LR逻辑回归</h3><p>● <strong>原理介绍</strong></p><p>二分类算法，也可以用于多分类问题。</p><p>逻辑回归分为两部分：逻辑和回归。</p><p>线性回归模型里的因变量是连续变量，而逻辑回归里的因变量可以理解为分类变量，现在我们需要用回归模型去表示这个分类，比如说大或小，黑或白。那么考虑类别之间相对的关系，我们可以用概率来表示这个问题，比如说分类为黑的概率大于白的概率时，就把样本预测为黑。所以我们可以定制一个映射关系，将负无穷到正无穷之间的数值映射成概率值，即0-1之间，就可以解决线性回归到分类问题的过渡。</p><p>●<strong>为什么激活函数用sigmoid？</strong></p><p>因为伯努利的指数族分布形式为:</p><div align="center"><img src="'+l+'" title="" alt="" data-align="center"></div><p>在这个式子中，对照指数族分布的形式:</p>',13),A=p("p",{class:"katex-block"},[p("span",{class:"katex-display"},[p("span",{class:"katex"},[p("span",{class:"katex-mathml"},[p("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[p("semantics",null,[p("mrow",null,[p("mi",null,"μ"),p("mo",null,"="),p("mfrac",null,[p("mn",null,"1"),p("mrow",null,[p("mn",null,"1"),p("mo",null,"+"),p("msup",null,[p("mi",null,"e"),p("mrow",null,[p("mo",null,"−"),p("mi",null,"θ")])])])])]),p("annotation",{encoding:"application/x-tex"}," \\mu=\\frac{1}{1+e^{-\\theta}} ")])])]),p("span",{class:"katex-html","aria-hidden":"true"},[p("span",{class:"base"},[p("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),p("span",{class:"mord mathnormal"},"μ"),p("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),p("span",{class:"mrel"},"="),p("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),p("span",{class:"base"},[p("span",{class:"strut",style:{height:"2.0908em","vertical-align":"-0.7693em"}}),p("span",{class:"mord"},[p("span",{class:"mopen nulldelimiter"}),p("span",{class:"mfrac"},[p("span",{class:"vlist-t vlist-t2"},[p("span",{class:"vlist-r"},[p("span",{class:"vlist",style:{height:"1.3214em"}},[p("span",{style:{top:"-2.314em"}},[p("span",{class:"pstrut",style:{height:"3em"}}),p("span",{class:"mord"},[p("span",{class:"mord"},"1"),p("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),p("span",{class:"mbin"},"+"),p("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),p("span",{class:"mord"},[p("span",{class:"mord mathnormal"},"e"),p("span",{class:"msupsub"},[p("span",{class:"vlist-t"},[p("span",{class:"vlist-r"},[p("span",{class:"vlist",style:{height:"0.7751em"}},[p("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[p("span",{class:"pstrut",style:{height:"2.7em"}}),p("span",{class:"sizing reset-size6 size3 mtight"},[p("span",{class:"mord mtight"},[p("span",{class:"mord mtight"},"−"),p("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])])])])])])])])]),p("span",{style:{top:"-3.23em"}},[p("span",{class:"pstrut",style:{height:"3em"}}),p("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),p("span",{style:{top:"-3.677em"}},[p("span",{class:"pstrut",style:{height:"3em"}}),p("span",{class:"mord"},[p("span",{class:"mord"},"1")])])]),p("span",{class:"vlist-s"},"​")]),p("span",{class:"vlist-r"},[p("span",{class:"vlist",style:{height:"0.7693em"}},[p("span")])])])]),p("span",{class:"mclose nulldelimiter"})])])])])])],-1),M=t('<p>● <strong>为什么要用指数族分布？</strong></p><p>因为指数族分布是给定某些统计量下熵最大的分布，例如伯努利分布就是只有两个取值且给定期望值为下的熵最大的分布。</p><p>● <strong>为什么要使用熵最大的分布？</strong></p><p>最大熵理论</p><p>https://zhuanlan.zhihu.com/p/59137998</p><p>● <strong>交叉熵公式推导</strong></p><p>问题描述</p><p>对逻辑回归交叉熵损失函数</p><div align="center"><img src="'+h+'" title="" alt="" data-align="center"></div><p>注意到</p><div align="center"><img src="'+g+'" title="" alt="" data-align="center"></div><p>即有</p><div align="center"><img src="'+c+'" title="" alt="" data-align="center"></div><p>那么</p><div align="center"><img src="'+d+'" title="" alt="" data-align="center"></div><p>● <strong>逻辑回归的参数能不能初始化为0</strong></p><p>神经网络里不可以，LR里可以，因为反向传播的时候(y^-y)*x，参数更新的时候求导的值会因为x的不同而不同，而且不为0，模型的权重可以得到更新。当b初始化为0的时候，同理，loss对b的导数也不为0，可以得到更新。</p><p>● <strong>为什么用交叉熵？</strong></p><p>两个角度，</p><p>1、从极大似然估计的角度理解</p><p>根据逻辑回归的计算公式，我们可以知道对应为1和0的样本的概率：</p><div align="center"><img src="'+m+'" title="" alt="" data-align="center"></div><p>然后就可以计算出现这些样本的似然函数，就是把每一个样本的概率乘起来：</p><div align="center"><img src="'+u+'" title="" alt="" data-align="center"></div><p>但是这个形式是连乘的，并不好求，所以一般我们会把他取对数，转化为累加的形式，就得到对数似然函数：</p><div align="center"><img src="'+b+'" title="" alt="" data-align="center"></div><p>这时候呢，我们就可以通过最大化这个对数似然函数的方式来求得逻辑回归模型中的w和b，把上面的式子加个负号，就是通过最小化这个负对数似然函数来求得w和b，就可以通过梯度下降法来进行求解了。</p><p>可以发现，通过数理统计中的极大似然估计方法，也可以得到逻辑回归的损失函数。</p><p>2、从KL散度的角度理解</p><p>如果对于同一个随机变量X有两个单独的概率分布p(X)和q(X) ，那么我们就可以用KL散度来衡量这两个分布的差异：</p><div align="center"><img src="'+_+'" title="" alt="" data-align="center"></div><p>我们将 p(x) 定义为真实的概率分布， q(x) 定义为模型预测的概率分布，我们希望预测的概率分布与真实的概率分布差异越小越好，也就是使得KL散度越小越好，而 p(x) 是在数据集确定之后就确定下来的了，所以我们只要使得 q(x) 尽可能地接近 p(x) 就可以了。</p><p>将这个KL散度的公式展开可以得到：</p><div align="center"><img src="'+f+'" title="" alt="" data-align="center"></div><p>所以根据上面那个展开的公式，就可以发现KL散度=交叉熵-真实分布的信息熵，而这个真实分布的信息熵是根据 p(x) 计算得到的，而这个 p(x) 是在数据集确定之后就确定下来的了，这一项就可以当成一个常数项，所以我们如果想让KL散度越小，只需要让交叉熵越小越好了，因此就可以直接将逻辑回归的损失函数直接定义为交叉熵。</p><p>https://zhuanlan.zhihu.com/p/386406590</p><h2 id="集成学习" tabindex="-1"><a class="header-anchor" href="#集成学习" aria-hidden="true">#</a> 集成学习</h2><p>● <strong>bagging和boosting的区别</strong></p><p>1）样本选择上：</p><p>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。</p><p>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</p><p>2）样例权重：</p><p>Bagging：使用均匀取样，每个样例的权重相等</p><p>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。</p><p>3）预测函数：</p><p>Bagging：所有预测函数的权重相等。</p><p>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</p><p>4）并行计算：</p><p>Bagging：各个预测函数可以并行生成</p><p>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p><p>5）方差偏差分解：</p><p>Bagging：降低方差</p><p>Boosting：降低偏差</p><p>对于Bagging算法来说，由于我们并行的训练很多的分类器的目的就是降低这个方差。所以对于每个基分类器的目的就是如何降低这个偏差，所以我们会采用深度很深并且不剪枝的决策树。这也是为什么随机森林的树的深度往往大于GBDT的树的深度的原因。</p><p>● <strong>为什么Bagging能降低方差</strong></p><p>对每个样本 x，假设单模型（如决策树）在不同数据集上学习得到的模型对样本 x的输出服从某种分布，Bagging的集成策略为对弱学习器求平均</p><div align="center"><img src="'+T+'" title="" alt="" data-align="center"></div><p>由于子样本集的相似性以及使用的是同种模型，因此各模型有近似相等的bias和variance（事实上，各模型的分布也近似相同，但不独立）。</p><p>● <strong>为什么偏差不变</strong></p><p>单个模型和集成之后的模型关于样本的预测值的期望一样，因此单个模型的偏差决定集成之后的模型的偏差，因此要尽量选择偏差比较小的单模型，通常来说模型越复杂偏差越小，因此尽量选择比较复杂的单模型，如深度很深或者不剪枝的决策树。</p><p>算法通过迭代构建一系列的分类器，每次分类都将上一次分错的数据权重提高一点再进行下一个分类器分类，这样最终得到的分类器在测试数据与训练数据上都可以得到比较好的成绩。其代表算法为AdaBoost、GBDT、XGBoost。</p><p>而对于Boosting来说，每一步我们都会在上一轮的基础上更加的拟合原数据，所以可以保证偏差，所以对于每个基分类器来说，问题就是如何选择方差更小的分类器，即更简单的弱分类器，所以我们选择深度很浅的决策树。</p><p>从优化角度来看，是用forward-stagewise这种贪心法去最小化损失函数。因此boosting是在sequential地最小化损失函数，其bias自然逐步下降。但由于是采取这种sequential、adaptive的策略，各子模型之间是强相关的，于是子模型之和并不能显著降低variance。所以说boosting主要还是靠降低bias来提升预测精度。</p><p>● <strong>方差偏差分解</strong></p><p>Bias：Bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异；</p><p>方差：Variance则是“不同的训练数据集训练出的模型”的输出值之间的差异。</p><p>Boosting：从偏差—方差分解角度看，降低偏差。\vBagging：从偏差—方差分解角度看，降低方差。</p><p>偏差指的是算法的期望预测与真实值之间的偏差程度，反映了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。</p>',68),k={href:"https://cloud.tencent.com/developer/article/1483259",target:"_blank",rel:"noopener noreferrer"},G=t('<p>● <strong>随机森林和GBDT</strong></p><p>https://zhuanlan.zhihu.com/p/37676630</p><p>● <strong>GBDT算法以及GBDT做分类</strong></p><p>GBDT无论用于分类还是回归，一直使用的是CART回归树。</p><p>GBDT二分类算法，就是用多棵CART回归树拟合结果为1的对数几率，损失函数使用对数损失函数，只是需要将预测值yi&#39;(预测为1的概率)用回归树预测的对数几率F(x)来代替，然后每轮再去拟合残差即可，得到最终分类器输出之后，将输出经过sigmoid函数即可得到预测结果为1的概率。</p><p>https://zhuanlan.zhihu.com/p/508713509</p><p>● <strong>GBDT，XGBoost，LightGBM</strong></p><p>https://zhuanlan.zhihu.com/p/148050748</p><h2 id="决策树" tabindex="-1"><a class="header-anchor" href="#决策树" aria-hidden="true">#</a> 决策树</h2><p>https://zhuanlan.zhihu.com/p/266880465</p><p>https://zhuanlan.zhihu.com/p/267368825</p><h2 id="em算法" tabindex="-1"><a class="header-anchor" href="#em算法" aria-hidden="true">#</a> EM算法</h2><p>● <strong>原理</strong></p><p>已知的是观察数据，未知的是隐含数据和模型参数</p><p>EM 算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含参数（EM 算法的 E 步），接着基于观察数据和猜测的隐含参数一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。由于我们之前的隐含参数是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。我们基于当前得到的模型参数，继续猜测隐含参数（EM算法的 E 步），然后继续极大化对数似然，求解我们的模型参数（EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。</p><p>一个最直观了解 EM 算法思路的是 K-Means 算法。在 K-Means 聚类时，每个聚类簇的质心是隐含数据。我们会假设 K 个初始化质心，即 EM 算法的 E 步；然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，即 EM 算法的 M 步。重复这个 E 步和 M 步，直到质心不再变化为止，这样就完成了 K-Means 聚类。</p><p>● <strong>收敛性</strong></p><p>EM 算法可以保证收敛到一个稳定点，但是却不能保证收敛到全局的极大值点，因此它是局部最优的算法，当然，如果我们的优化目标是凸的，则EM算法可以保证收敛到全局极大值，这点和梯度下降法这样的迭代算法相同。</p><h2 id="过拟合" tabindex="-1"><a class="header-anchor" href="#过拟合" aria-hidden="true">#</a> 过拟合</h2><p>● <strong>解决过拟合的方法</strong></p><p>1、  模型角度：正则化、BatchNorm和LayerNorm、Dropout</p><p>2、  数据角度：增加训练数据、数据增强、标签平滑、引入先验知识</p><p>3、  其他方法：交叉验证，预训练等</p><p>● <strong>Dropout为什么可以解决过拟合？</strong></p><p>每次做完dropout，对于某些神经网络单元，相当于从原始的网络以概率P暂时从网络中进行丢弃，找到一个更瘦的网络。</p><p>Dropout的意义在于，减小了不同神经元的依赖。有些中间输出，在给定的训练集上，可能发生只依赖某些神经元的情况，这就会造成对训练集的过拟合。而随机关掉一些神经元，可以让更多神经元参与到最终的输出当中。我觉得dropout方法也可以看成，联合很多规模比较小的网络的预测结果，去获取最终的预测。</p><h2 id="归一化" tabindex="-1"><a class="header-anchor" href="#归一化" aria-hidden="true">#</a> 归一化</h2><p>● <strong>为什么要做归一化</strong></p><p>把数据映射到0-1范围内,使得处理过程更加便捷;提高不同数据特征之间的可比性。</p><p>● <strong>各种归一化的区别和优缺点</strong></p><p>最常用的有z标准化和最小最大标准化方法。z标准化一般在处理近似正态分布的数据比较合适，否则使用最小最大标准化，将数据的范围压缩到0~1区间。</p><p>● <strong>为什么NLP不用batchnorm？</strong></p><p>LayerNorm是对特征维度，也就是句子中一个Tokens的向量表示进行归一化，BatchNorm是对batch_size*seq_size维度范围，也就是一个batch中所有Tokens向量的第i维进行归一化。NLP不使用BatchNorm有以下几个原因：</p><p>（1）一个batch中不同句子字符长度不等，虽然通过补0或截断后能达到相同的句子长度，对这样一个batch进行BatchNorm，反而会加大特征的方差。</p><p>（2） NLP中一个batch中所有Tokens的第i维向量关联性不大，对他们进行BatchNorm会损失Tokens之间的差异性。而我们想保留不同Tokens之间的差异性，所以不在该维度进行Norm</p><p>（3）有实验证明，将LayerNorm换为BatchNorm后，会使得训练中Batch的统计量以及统计量贡献的梯度不稳定，Batch的统计量就是Batch中样本的均值和方差，Batch的统计量不稳定也就是当前Batch的均值和运行到当前状态累加得到的均值间的差值有的大，有的小，方差也是类似的情况。</p><p>（4）LayerNorm对self-attention处理累加得到向量进行归一化，降低其方差，加速收敛。</p><h2 id="正则化" tabindex="-1"><a class="header-anchor" href="#正则化" aria-hidden="true">#</a> 正则化</h2><p>● <strong>正则化怎么做，L1和L2</strong></p><p>模型复杂度如果过高，会出现过拟合的情况，正则化的主要目的就是控制模型复杂度，减小过拟合。最基本的正则化方法是在原目标（代价）函数中添加惩罚项，对复杂度高的模型进行“惩罚”。这个惩罚项是一个参数a乘以一个函数，a是用于控制正则化强弱的。对于l1正则化来说，函数是l1范数，对于l2来说是l2范数。</p><p>L1范数：向量中各个元素绝对值之和\vL2范数：向量各元素的平方和然后求平方根</p><p>● <strong>现象</strong></p><p>l2正则化的效果是对原最优解的每个元素进行不同比例的放缩；l1正则化则会使原最优解的元素产生不同量的偏移，并使某些元素为0，从而产生稀疏性。</p><p>● <strong>先验</strong></p><p>l1正则化可通过假设权重w的先验分布为拉普拉斯分布，由最大后验概率估计导出；</p><p>l2正则化可通过假设权重w的先验分布为高斯分布，由最大后验概率估计导出。</p><h2 id="初始化" tabindex="-1"><a class="header-anchor" href="#初始化" aria-hidden="true">#</a> 初始化</h2><p>● <strong>不同网络的初始化有什么区别</strong></p><p>全0初始化</p><p>全0初始化是最差的初始化方法，只适用于单神经元神经网络。对于任何具有隐藏层的神经网络，如果初始化时所有的权重都是相同的，则任意一层多神经元的效果都与单神经元相同，无法对多特征进行学习，白白浪费计算力。</p><p>而全0初始化又是相同权重初始化的一种特殊情况，根据反向传播的链式法则，具有隐藏层的神经网络参数将永远不会更新，cost函数永远不会下降。</p><p>随机初始化</p><p>随机初始化是最常见的一种初始化方法：W参数全部随机初始化，b参数全部初始化为0。在python中，使用np.random.randn和np.zeros函数初始化即可。</p><p>Xavier初始化</p><p>条件：正向传播时，激活值的方差保持不变；反向传播时，关于状态值的梯度的方差保持不变。其中，激活值是激活函数输出的值，状态值是输入激活函数的值。</p><p>初始化方法为，</p><div align="center"><img src="'+x+'" title="" alt="" data-align="center"></div><p>He初始化（Kaiming初始化）</p><p>条件：正向传播时，状态值的方差保持不变；反向传播时，关于激活值的梯度的方差保持不变。</p><p>初始化方法为（适用于ReLU），</p><div align="center"><img src="'+B+'" title="" alt="" data-align="center"></div><p>在python中，实现方式是在随机初始化的基础上，乘以np.sqrt(u / layers_dims[l - 1])。layers_dims[l - 1]即上一层神经元的个数，u是一个可调的参数。经实践，对于tanh，u的取值为1；对于relu，u的取值为2。</p><p>He初始化方法主要适用于ReLU和Leaky ReLU等激活函数。</p><p>● <strong>神经网络的隐层可以全部初始化为0吗</strong></p><p>将偏置项b初始化为0实际上是可行的，但把W初始化成全零就成问题了，它的问题在于给神经网络输入任何的样本，隐藏层的两个单元都是相同的值。每个单元的节点的权重是一样的，即权重矩阵的每一行是相同的。那么在反向传播的时候，所有节点的梯度改变是一样的，最后计算出来输入层与隐藏层之间的参数更新都是一样的。</p><p>一直这样迭代下去，神经网络的每一次正向和反向传播，隐藏层的每个激活单元其实都在计算同样的东西，其实也就是一个&quot;对称网络&quot;，这种网络无法学习到什么有趣的东西，因为每个隐藏层的激活单元都在计算同样的东西，那么隐藏层其实相当于只有一个单元，因此神经网络的W参数矩阵不能随机初始化为0。</p><h2 id="激活函数" tabindex="-1"><a class="header-anchor" href="#激活函数" aria-hidden="true">#</a> 激活函数</h2><p>一般会问你某个激活函数（比如sigmoid）的公式和优缺点，比如在问逻辑回归相关的题的时候混杂着问。</p><p>● <strong>作用</strong></p><p>网络只是线性模型，只能把输入线性组合再输出，不能学到复杂的映射关系，所以用激活函数做非线性的转换。</p><h2 id="损失函数" tabindex="-1"><a class="header-anchor" href="#损失函数" aria-hidden="true">#</a> 损失函数</h2><p>● <strong>二分类的损失函数</strong></p><p>交叉熵</p><p>● <strong>为什么分类不用MSE</strong></p><p>用方差容易出现多个局部最优解（即非凸函数），这样很难找到全局最优训练出好的模型，这样很依赖初始权值的起点。反之，用交叉熵就很容易找到全局最优，因为是代价函数是大部分情况是凸函数。</p><h2 id="信息论" tabindex="-1"><a class="header-anchor" href="#信息论" aria-hidden="true">#</a> 信息论</h2><p>https://www.zhihu.com/question/591173254/answer/2950347352?utm_id=0</p><p>https://zhuanlan.zhihu.com/p/292434104?utm_id=0</p><h2 id="样本不均衡的解决方案" tabindex="-1"><a class="header-anchor" href="#样本不均衡的解决方案" aria-hidden="true">#</a> 样本不均衡的解决方案</h2><p>● <strong>过采样</strong></p><p>随机采样：从少数类的样本中进行随机采样来增加新的样本</p><p>SMOTE: 对于少数类样本a, 随机选择一个最近邻的样本b, 然后从a与b的连线上随机选取一个点c作为新的少数类样本;</p><p>ADASYN: 关注的是在那些基于K最近邻分类器被错误分类的原始样本附近生成新的少数类样本</p><p>● <strong>降采样</strong></p><p>（1）随机降采样</p><p>从多数类中随机选择一些样样本组成样本集。然后将新样本集与少数类样本集合并。</p><p>（2）Edited Nearest Neighbor (ENN)</p><p>遍历多数类的样本，如果他的大部分k近邻样本都跟他自己本身的类别不一样，我们就将他删除；</p><p>（3）Repeated Edited Nearest Neighbor（RENN）</p><p>重复以上ENN的过程直到没有样本可以被删除；</p><p>（4）Tomek Link Removal</p><p>其思想是，类别间的边缘可能增大分类难度，通过去除边缘中的多数类样本可以使得类别间margin更大，便于分类。具体方法是：如果有两个不同类别的样本，它们的最近邻都是对方，也就是A的最近邻是B，B的最近邻是A，那么A,B就是Tomek link，我们要做的就是将所有Tomek link都删除掉。那么一个删除Tomek link的方法就是，将组成Tomek link的两个样本，如果有一个属于多数类样本，就将该多数类样本删除掉。这样我们可以发现正负样本就分得更开了。</p><p>● <strong>带权重的loss</strong></p>',93),z={href:"https://blog.csdn.net/dfly_zx/article/details/123152907",target:"_blank",rel:"noopener noreferrer"},R=t('<h2 id="数据预处理" tabindex="-1"><a class="header-anchor" href="#数据预处理" aria-hidden="true">#</a> 数据预处理</h2><p>连续特征归一化，离散特征one-hot编码</p><h2 id="梯度消失和梯度爆炸" tabindex="-1"><a class="header-anchor" href="#梯度消失和梯度爆炸" aria-hidden="true">#</a> 梯度消失和梯度爆炸</h2><p>● <strong>梯度消失和梯度爆炸的原因</strong></p><p>当梯度消失发生时，最后一个隐层梯度更新基本正常，但是越往前的隐层内更新越慢，甚至有可能会出现停滞，此时，多层深度神经网络可能会退化为浅层的神经网络（只有后面几层在学习），因为浅层基本没有学习，对输入仅仅做了一个映射而已。</p><p>当梯度爆炸发生时，最后一个隐层梯度同样更新正常，但是向前传播的梯度累计过程中，浅层网络可能会产生剧烈的波动，从而导致训练下来的特征分布变化很大，同时输入的特征分布可能与震荡幅度不同，从而导致最后的损失存在极大的偏差。</p><p>梯度消失和梯度爆炸本质上是一样的，均因为网络层数太深而引发的梯度反向传播中的连乘效应。</p><p>● <strong>解决方案</strong></p><p>权重初始化+激活函数</p><p>Batchnorm</p><h2 id="优化器" tabindex="-1"><a class="header-anchor" href="#优化器" aria-hidden="true">#</a> 优化器</h2><p>● <strong>作用</strong></p><p>用来更新和计算影响模型训练和模型输出的网络参数,使其逼近或达到最优值,从而最小化(或最大化)损失函数。</p><p>● <strong>各种优化器原理、公式、公式符号的意思</strong></p><p>https://zhuanlan.zhihu.com/p/64113429</p><p>● <strong>从SGD到Adam做了哪些改进</strong></p><p>自适应的学习率、动量</p><p>● <strong>从SGD到Adam做了哪些改进</strong></p><p>Adamw 即 Adam + weight decate ,效果与 Adam + L2正则化相同，但是计算效率更高,因为L2正则化需要在loss中加入正则项，之后再算梯度，最后反向传播，而Adamw直接将正则项的梯度加入反向传播的公式中，省去了手动在loss中加正则项这一步。</p><h2 id="评价指标" tabindex="-1"><a class="header-anchor" href="#评价指标" aria-hidden="true">#</a> 评价指标</h2><p>Precision，也叫精确率。是指被预测为阳性的样本中，有多少是预测正确的（针对于预测结果来说的）</p><p>Precision=TP/（TP+FP）</p><p>准确率Accuracy = （TPR+TNR）/2</p><p>AUC（area under Curve），是ROC曲线下的面积，具体概念这里不赘述了。AUC能反映模型的排序能力，他反应的是一个相对性，即item a排在item b之前的能力；但是它不反应绝对性，例如，0.9排在0.1前面和0.5排在0.1前面对他来说是一样的。</p><p>为什么AUC和logloss比accuracy更常用呢？因为很多机器学习的模型对分类问题的预测结果都是概率，如果要计算accuracy，需要先把概率转化成类别，这就需要手动设置一个阈值，如果对一个样本的预测概率高于这个预测，就把这个样本放进一个类别里面，低于这个阈值，放进另一个类别里面。所以这个阈值很大程度上影响了accuracy的计算。使用AUC或者logloss可以避免把预测概率转换成类别。（前面讲了ROC是怎么画图的，画图的时候用的就是概率，并没有转换成类别，AUC就是ROC曲线下的面积）</p><p>● <strong>工业界为什么用auc？</strong></p><p>1.  AUC指标本身和模型预测score绝对值无关，只关注排序效果，因此特别适合排序业务，为何与模型预测score值无关为何是很好的特性呢?假设你采用precision、F1等指标，而模型预测的score是个概率值，就必须选择一个闻值来决定哪些样本预测是1哪些是0，不同的闻值选择，precision的值会不同，而AUC可以直接使用score本身，参考的是相对顺序，更加好用。</p><p>2.  AUC对均匀正负样本采样不敏感。正由于AUC对分值本身不敏感，故常见的正负样本采样，并不会导致auc的变化。比如在点击率预估中，处于计算资源的考虑，有时候会对负样本做负采样，但中于采样完后并不影响正负样本的顺序分布。即假设采样是随机的，采样完成后，给定一条正样本，模型预测为score1，由于采样随机，则大于score1的负样本和小于score1的负样本的比例不会发生变化。</p><p>● <strong>代码</strong></p><p>https://zhuanlan.zhihu.com/p/82978513?utm_id=0</p><h2 id="bert和transformer" tabindex="-1"><a class="header-anchor" href="#bert和transformer" aria-hidden="true">#</a> BERT和Transformer</h2><p>● <strong>介绍一下BERT/Transformer</strong></p><p>● <strong>BERT的两个训练任务</strong>？</p><p>MLM和Next Sentence Prediction</p><p>● <strong>BERT的优化器（AdamW）？和Adam的区别（前面写了）？</strong></p><p>● <strong>Attention和self-attention的区别</strong></p><p>self-attention比attention约束条件多了两个：\v1. Q=K=V（同源）\v2. Q，K，V需要遵循attention的做法</p><p>● <strong>Self-attention的公式，计算过程</strong></p><p>首先QKV是由输入序列X 经过矩阵变换得到的，可以认为是对原始输入X做了某种特征提取，不直接使用X是为了提高模型的可学习性。其中Q和K是用来计算词语之间相似度的，即关注程度，V可以理解为某个词的特征表征，与QK计算到的权重系数相乘，然后求和，即实现了加权求和，实现了注意力机制。</p><p>为什么要除以一个维度：缩放后后注意力分数矩阵中分数的方差由原来的缩小到了1，方差越小，点积的数量级越小。</p><p>● <strong>多头的意义</strong></p><p>多头注意力增加复杂度吗？不增加</p><p>多头的意义？多头注意力允许模型在不同位置共同关注来自不同表示子空间的信息。使用一个单注意力头，会抑制这种情况。</p><p>在这篇论文中 http://arxiv.org/pdf/1905.0941 讨论了多头的作用，发现并不是头越多越好，去掉一些头效果依然有不错的效果（而且效果下降可能是因为参数量下降），这是因为在头足够的情况下，这些头已经能够有关注位置信息、关注语法信息、关注罕见词的能力了，再多一些头，无非是一种 enhance 或 noise 而已。</p><p>● <strong>对比LSTM，Transformer的优点</strong>？</p><p>上下文感知、并行计算</p><p>● <strong>BERT怎么解决OOV out of vobulary</strong></p><p>如果一个单词不在词表中，则按照subword的方式逐个拆分token，如果连逐个token都找不到，则直接分配为[unknown]</p><h2 id="chatgpt" tabindex="-1"><a class="header-anchor" href="#chatgpt" aria-hidden="true">#</a> ChatGPT</h2><p>● <strong>对ChatGPT发展的看法</strong></p><p>自己编！！！</p><p>● <strong>对比GPT-3的性能提升</strong></p><p>ChatGPT对比GPT-3的性能提升主要来源于以下四个方面：</p><p>（1）大模型。大模型拥有更多的文本数据和代码数据，这是ChatGPT具有优秀推理能力的基础。</p><p>（2）用代码进行预训练。代码和文本相比，需要更长的语言依赖如函数调用。因此，在代码上进行预训练，拆分代码流程，这使得ChatGPT的语言理解能力更为强大，能够得到更好的训练效果。</p><p>（3）Prompt/Instruction Tuning。用提示/指令模版去进行微调，使得语言模型能够适应人的语言逻辑，而不是人类去理解语言模型的参数。</p><p>（4）人类反馈的强化学习（RLHF）。ChatGPT使用了真实的用户反馈数据，使得生成结果在多样性和安全性等方面更符合人类的期望。</p><p>● <strong>RLHF原理</strong></p><p>RLHF原理：</p><p>RLHF的训练过程可以分解为三个核心步骤：</p><p>1、选择一个经典的预训练语言模型作为初始模型，例如OpenAI在InsturctGPT中使用小规模参数版本的GPT-3，</p><p>2、收集上述预训练语言模型产生的数据来训练一个奖励模型，这个模型可以看作一个判别式的语言模型，输入是prompt和模型的回答，输出是人类的满意度，但是这里标注人员的任务是对生成的回答进行排序，比如说给定同一个prompt，让两个语言模型同时生成文本，然后比较这两段文本哪个好</p><p>3、通过强化学习来基于奖励模型优化初始的语言模型，强化学习的策略就是基于该语言模型，接收prompt作为输入，然后输出一系列文本（或文本的概率分布）；动作空间就是词表所有token在所有输出位置的排列组合；观察空间则是可能的prompt序列；奖励函数则是刚才的奖励模型的计算结果再叠加一个约束项。</p><p>（约束项：假设用一个prompt得到两个模型的输出y1和y2，再用奖励模型打分，这两个打分的差值作为一个信号，用KL散度计算奖励/惩罚的大小，y2打分比y1高得越多奖励越大，反之惩罚越大。这样是为了防止当前模型围着初始模型“绕圈”，避免模型通过一些取巧的方式获得高额reward）</p><p>最后根据Proximal Policy Optimization(PPO)算法更新模型参数。</p><h2 id="大模型相关" tabindex="-1"><a class="header-anchor" href="#大模型相关" aria-hidden="true">#</a> 大模型相关</h2><h3 id="_1-基础部分" tabindex="-1"><a class="header-anchor" href="#_1-基础部分" aria-hidden="true">#</a> 1. 基础部分</h3><p>（这部分答案请参考我之前的帖子）</p><p>1、self-attention的公式及参数量，为什么用多头，为什么要除以根号d</p><p>2、BERT和GPT的训练方式（预训练任务、训练细节）</p><p>3、transformer架构</p><p>*注意要会手撕self-attention，熟知公式里的参数是做什么的，其实没有大模型之前面试就常考，大模型出来以后更是常考……</p><h3 id="_2-大模型的模型结构" tabindex="-1"><a class="header-anchor" href="#_2-大模型的模型结构" aria-hidden="true">#</a> 2. 大模型的模型结构</h3><p>一般指一亿参数以上的模型。</p><p>目前以Transformer为基础自回归生成大致可以分为三种架构：</p><ul><li><p>Encoder-only的模型，如BERT</p></li><li><p>Encoder-Decoder的模型，如T5。</p></li><li><p>Decoder-Only的模型，如GPT系列。</p></li></ul><p>用GPT-4举例，它使用Transformer的Decoder结构，并对Transformer Decoder进行了一些改动。-&gt;介绍Transformer Decoder的结构</p><h3 id="_3-chatgpt对比gpt-3的性能提升主要来源于以下四个方面" tabindex="-1"><a class="header-anchor" href="#_3-chatgpt对比gpt-3的性能提升主要来源于以下四个方面" aria-hidden="true">#</a> 3. ChatGPT对比GPT-3的性能提升主要来源于以下四个方面：</h3><ul><li><p>大模型。大模型拥有更多的文本数据和代码数据，这是ChatGPT具有优秀推理能力的基础。</p></li><li><p>用代码进行预训练。代码和文本相比，需要更长的语言依赖如函数调用。因此，在代码上进行预训练，拆分代码流程，这使得ChatGPT的语言理解能力更为强大，能够得到更好的训练效果。</p></li><li><p>Prompt/Instruction Tuning。用提示/指令模版去进行微调，使得语言模型能够适应人的语言逻辑，而不是人类去理解语言模型的参数。</p></li><li><p>人类反馈的强化学习（RLHF）。ChatGPT使用了真实的用户反馈数据，使得生成结果在多样性和安全性等方面更符合人类的期望。</p></li></ul><h3 id="_4-instructgpt和chatgpt模型中使用的关键技术-sft-rlhf" tabindex="-1"><a class="header-anchor" href="#_4-instructgpt和chatgpt模型中使用的关键技术-sft-rlhf" aria-hidden="true">#</a> 4. InstructGPT和ChatGPT模型中使用的关键技术（SFT-&gt;RLHF）</h3><p>训练过程可以分解为三个核心步骤：</p><ul><li>SFT：生成模型GPT的有监督精调（supervised fine-tuning）。选择一个经典的预训练语言模型作为初始模型，例如OpenAI在InstructGPT中使用小规模参数版本的GPT-3，</li></ul><p>-&gt;RLHF</p><ul><li><p>RM：奖励模型的训练（reward model training）。收集上述预训练语言模型  产生的数据来训练一个奖励模型，这个模型可以看作一个判别式的语言模型，输入是prompt和模型的回答，输出是人类的满意度，但是这里标注人员的任务是对生成的回答进行排序，比如说给定同一个prompt，让两个语言模型同时生成文本，然后比较这两段文本哪个好</p></li><li><p>PPO：近端策略优化模型（Proximal Policy Optimization）。通过强化学习来基于奖励模型优化初始的语言模型，强化学习的策略就是基于该语言模型，接收prompt作为输入，然后输出一系列文本（或文本的概率分布）；动作空间就是词表所有token在所有输出位置的排列组合；观察空间则是可能的prompt序列；奖励函数则是刚才的奖励模型的计算结果再叠加一个约束项。</p></li></ul><p>（约束项：假设用一个prompt得到两个模型的输出y1和y2，再用奖励模型打分，这两个打分的差值作为一个信号，用KL散度计算奖励/惩罚的大小，y2打分比y1高得越多奖励越大，反之惩罚越大。这样是为了防止当前模型围着初始模型“绕圈”，避免模型通过一些取巧的方式获得高额reward）</p><p>最后根据PPO算法更新模型参数。</p><h3 id="_5-大模型中常用的位置编码" tabindex="-1"><a class="header-anchor" href="#_5-大模型中常用的位置编码" aria-hidden="true">#</a> 5. 大模型中常用的位置编码</h3><p>改写自某乎：归来仍是少年</p><p>详解点链接https://zhuanlan.zhihu.com/p/631003833</p><p>位置编码分为绝对位置编码和相对位置编码，以前的语言模型如BERT主要使用绝对位置编码，比如三角函数位置编码，但最大的长度是512，所以需要截断输入，所以后续的大模型主要研究相对位置编码。</p><p>（考虑到面试一般时间比较紧，介绍常用的两三个和他们的区别就行）</p><ul><li>ROPE（旋转位置编码）</li></ul><p>谷歌PaLM和LLaMA中采用的位置编码，通过复数形式来改进三角函数绝对位置编码。</p><ul><li>Alibi 位置编码（Attention with Linear Biases）</li></ul><p>Alibi 位置编码主要是Bloom模型采用，Alibi 的方法也算较为粗暴，是直接作用在attention score中，给 attention score 加上一个预设好的偏置矩阵，相当于 q 和 k 相对位置差 1 就加上一个 -1 的偏置。其实相当于假设两个 token 距离越远那么相互贡献也就越低。</p><p>区别：</p><p>Alibi 位置编码的外推性比旋转位置编码外推性要好一些，旋转位置编码也是基于正余弦三角式位置编码改进融入相对位置信息，但是正余弦三角式位置编码外推性缺点也很明显，看起来是不需要训练可以直接推演无限长度位置编码，但是忽略了一点就是周期性函数必须进行位置衰减，到远处的位置信息趋于直线震荡，基本很难有位置信息区分了，所以外推性比训练式的好不了多少，旋转位置编码基于此改进的自然也是如此。</p><p>Alibi 相当于在k和q向量内积上加入分数上的偏置，来体现出来位置差异性，针对于远距离衰减问题，则是通过softmax函数特性进行差异软放大，将token之间的位置差异性拉大，避免远距离时被衰减无限接近于0，因为直接作用在attention分数上，拉大远距离内积值，在训练的时候带来的位置差异性减少的问题会大大缓解，从而获得更远距离的外推性能。</p><h3 id="_6-大模型的微调方法" tabindex="-1"><a class="header-anchor" href="#_6-大模型的微调方法" aria-hidden="true">#</a> 6. 大模型的微调方法</h3><p>改写自某乎：YBH</p><p>详解https://zhuanlan.zhihu.com/p/636481171</p><ul><li>LoRA</li></ul><p>基于大模型的内在低秩特性，增加旁路矩阵来模拟full finetuning。具体来说，LoRA冻结一个预训练模型的矩阵参数，并选择用A和B矩阵来替代，在下游任务时只更新A和B。</p><ul><li>Adapter</li></ul><p>在预训练模型每一层（或某些层）中添加Adapter模块，微调时冻结预训练模型主体，由Adapter模块学习特定下游任务的知识。每个Adapter模块由两个Feed-Forward层组成，通常情况下将原始输入降维再升维，通过降维后的维度控制Adapter的参数量大小。</p><ul><li>Prefix-tuning</li></ul><p>前缀微调（prefix-tunning），用于生成任务的轻量微调。前缀微调将一个连续的特定于任务的向量序列添加到输入，称之为前缀，如下图中的红色块所示。与提示（prompt）不同的是，前缀完全由自由参数组成，与真正的token不对应。相比于传统的微调，前缀微调只优化了前缀。因此，我们只需要存储一个大型Transformer和已知任务特定前缀的副本，对每个额外任务产生非常小的开销。</p><ul><li>Prompt-tuning</li></ul><p>给每个任务定义自己的Prompt，拼接到数据上作为输入，同时freeze预训练模型进行训练，在没有加额外层的情况下，随着模型体积增大，Prompt-tuning的效果越来越好，最终追上精调的效果。</p><h2 id="_7-大模型相关问题" tabindex="-1"><a class="header-anchor" href="#_7-大模型相关问题" aria-hidden="true">#</a> 7. 大模型相关问题</h2><p>https://mp.weixin.qq.com/s/hvIAUeNGWJT1nK-IkGoQXA</p>',111);function E(N,w){const n=r("ExternalLinkIcon");return i(),o("div",null,[v,p("p",null,[a("原文链接："),p("a",P,[a("面试题答案"),s(n)])]),y,A,M,p("p",null,[p("a",k,[a("机器学习12：偏差-方差分解与bagging减少方差，boosting减少偏差-腾讯云开发者社区-腾讯云"),s(n)])]),G,p("p",null,[p("a",z,[a("样本不均衡及其解决办法_flare zhao的博客-CSDN博客"),s(n)])]),R])}const D=e(L,[["render",E],["__file","mianshijijin1.html.vue"]]);export{D as default};
